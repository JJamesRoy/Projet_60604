---
title: "Projet BIXI - Partie 2: Modèle de régression linéaire"
subtitle: "MATH60604 - Modélisation statistique"
author: "Abdoul Wassi Badirou, Alfred Assal, James Roy, Samuel Croteau"
date: "`r Sys.Date()`"
output:
  # pdf_document:
  #   toc: yes
  #   toc_depth: '3'
  bookdown::html_document2:
    toc: yes
    number_sections: yes
    toc_float:
      collapsed: no
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    extra_dependencies: flafter
params:
  created_date: "2023-09-12"
header-includes:
- \usepackage{tikz}
- \usepackage{subcaption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message = FALSE,warning = FALSE,error = TRUE, fig.pos = "H")
```

```{r lib}
library(tidyverse)
library(readxl)
library(knitr)
library(googleway)
```

# Note

Question : Comment maximiser les déplacements en Bixi pour accélérer la transition vers une économie verte et réduire l'impact sur l'environnement des moyens de transports.

Sous question :  
- Impact de l'événementiel (James)

- Est-ce que la densité de population du quartier a un impact sur l'utilisation des Bixi (Alfred)

- Attraits touristiques (https://donnees.montreal.ca/dataset/installations-recreatives-sportives-et-culturelles/resource/1c239e86-8b36-476c-bd51-91a3cd20f687) (https://donnees.montreal.ca/dataset/lieux-d-interet/resource/edce22aa-f7cc-495e-9c53-b367f68309f6) (Abdoul)

- Parc (https://donnees.montreal.ca/dataset/grands-parcs-parcs-d-arrondissements-et-espaces-publics) (Sam)


Leviers de Bixi : Publicité et marketing sur le service et l'abonnement. Programme incitation Bixi (alléger les stations ou remplir)

Variables cibles : n_tot et dur

Variables à ajouter : merge avec les autres données par sous-question


```{r read}
dat = read.csv("bixifull.csv")
```

```{r festival}
festivals <- data.frame(
  Start_Date = as.Date(c("2021-05-10", "2021-05-22", "2021-05-27", "2021-06-06", "2021-06-07",
                         "2021-06-07", "2021-06-07", "2021-06-11", "2021-06-13", "2021-06-14",
                         "2021-06-20", "2021-06-26", "2021-06-27", "2021-06-29", "2021-07-04",
                         "2021-07-05", "2021-07-06", "2021-07-09", "2021-07-10",
                         "2021-07-11", "2021-07-11", "2021-07-22", "2021-07-27", "2021-07-28",
                         "2021-08-02", "2021-08-06", "2021-08-07", "2021-08-08", "2021-08-09",
                         "2021-08-09", "2021-08-19", "2021-08-20", "2021-08-29", "2021-08-30")),
  End_Date = as.Date(c("2021-05-17", "2021-06-04", "2021-06-16", "2021-06-16", "2021-06-09",
                       "2021-06-16", "2021-06-09", "2021-06-16", "2021-06-16", "2021-06-22",
                       "2021-06-23", "2021-06-30", "2021-07-06", "2021-07-27", "2021-07-14",
                       "2021-07-07", "2021-07-06", "2021-07-14", "2021-07-21", "2021-07-28",
                       "2021-07-27", "2021-08-01", "2021-07-28", "2021-07-28", "2021-08-04",
                       "2021-08-14", "2021-08-11", "2021-08-18", "2021-08-10", "2021-08-18",
                       "2021-08-24", "2021-08-25", "2021-09-02", "2021-09-02"))
)

dates <- festivals %>%
  rowwise() %>%
  mutate(Date = list(seq(Start_Date, End_Date, by = "day"))) %>%
  unnest(Date)

result_df <- dates %>%
  group_by(Date) %>%
  summarize(festival = n())

dat$Date <- as.Date(paste("2021", dat$mm, dat$dd, sep = "-"))

dat <- dat %>%
  left_join(result_df, by = "Date")

dat$festival[is.na(dat$festival)] = 0
```

```{r rain}
dat = dat %>% mutate(rain_bin = ifelse(rain == 0, 0, 1)) %>% select(-X)
```

```{r wkend}
dat = dat %>% mutate(wkend = ifelse(wday == "Saturday" | wday == "Sunday",1,0))
col = c("mm", "dd", "mem", "arrond")
dat[col] = lapply(dat[col], factor)
```

```{r dat.mod}
var_mean= c("holiday", "temp", "rain", "festival", "rain_bin", "wkend")
var_sum = c("dur", "rev", "n_tot", "n_AM", "n_PM", "avg")

dat_mod = dat %>% select(-station, -name, -wday, -Date) %>% 
  group_by(mem, mm, dd, arrond) %>%
  summarise(across(all_of(var_mean), ~mean(., na.rm = TRUE)),
            across(all_of(var_sum), ~sum(., na.rm = TRUE))) # Sert à compiler les données selon les arrondissements par jour. On se débarasse ainsi des variables station. Cela fait qu'on peut analyser les données par arrondissement plutot que par station.

dat_mod = as.data.frame(dat_mod)

col = c("holiday", "wkend", "rain_bin")
dat_mod[col] = lapply(dat_mod[col], factor)
```

# Enrichissement des données {.unnumbered}
```{r importData, results='hide'}
bixi_raw_data_df = read.csv("bixi1.csv", sep=",", header = T)
head(bixi_raw_data_df)
```
```{r importMergeStationNameAndCoord, results='hide'}
# Importation des données de stations: Nom, latitude et Longitude
stations_raw_data_df=read.csv("2021_stations.csv", sep = ",", header = T, encoding='latin_1')
head(stations_raw_data_df)

#Jointure aux données bixi
bixi_with_name_df=merge(bixi_raw_data_df,stations_raw_data_df, by.x = "station",by.y = "pk", all.x = T, all.y = F)
head(bixi_with_name_df)
str(bixi_with_name_df)
```
```{r , results='hide'}
# Validons qu'il n'y a pas de données manquantes suite à l'ajout des noms des stations et leur coordonnées géographique
summary(bixi_with_name_df)
```
```{r, results='hide'}
#Importation des données de stations: Nom, arrondissement, latitude, longitude
bixi_stations_df=read.csv("bixi_stations_full.csv", sep = ",", header = T, encoding='latin_1')
head(bixi_stations_df)

# merge pour inclure les arrondissements
bixi_with_arrond_df=merge(bixi_with_name_df,bixi_stations_df, by.x = 'name',by.y = 'STATIONNAME', all.x = T, all.y = F)
head(bixi_with_arrond_df)
```
```{r}
summary(bixi_with_arrond_df)
```
```{r}
bixiWithArron_clean_df=data.frame(name=bixi_with_arrond_df$name,latitude=bixi_with_arrond_df$latitude,
      longitude=bixi_with_arrond_df$longitude,arrondissement=bixi_with_arrond_df$STATIONARRONDISSEMENT,
      bixi_with_arrond_df[,names(bixi_raw_data_df)])
```



# Introduction
- Déterminer les éléments qui influencent l'utilisation des bixi (nombre de déplacement) afin de proposer des stratégies qui permettraient de mieux la démocratiser.

- Déterminer le prix d'imputation des usagers membres qui permettrait de générer un revenu équivalent à celui des non-membres.

# Transformation variables d'intérêts

Nous allons observer nos variables d'intérêts pour voir si elles se prêtent à l'analyse statistique.

```{r histn, out.height = "30%", fig.cap="Distribution des déplacements totaux", fig.align='center'}
hist(dat_mod$n_tot, 
     ylab = "Fréquence", 
     xlab = "Nombre de déplacement totaux",
     main = "")
```

Dans la \@ref(fig:histn), on voit que les données de la variable `n_tot` ne sont pas normales, il faudrait les normaliser pour être capable de faire des analyses statistiques à l'aide de régression linéaire.

```{r histn2, out.height = "30%", fig.cap="Distribution du log des déplacements totaux", fig.align='center'}
dat_mod = dat_mod %>% mutate(n_tot_mod = log(n_tot))
hist(dat_mod$n_tot_mo, 
     ylab = "Fréquence", 
     xlab = "Nombre de déplacement totaux",
     main = "")
```

Maintenant, dans la \@ref(fig:histn2), on voit qu'avec une transformation logarithmique, les données se normalisent. Par contre, le côté gauche de la courbe est encore relevé, cela peut impacter l'inférence statistique que nous allons faire prochainement.

# Analyse de multicolinéarité
À faire si on a le temps.

# Parc

Données utilisées: <https://donnees.montreal.ca/dataset/installations-recreatives-sportives-et-culturelles/resource/1c239e86-8b36-476c-bd51-91a3cd20f687> <https://donnees.montreal.ca/dataset/grands-parcs-parcs-d-arrondissements-et-espaces-publics> <https://donnees.montreal.ca/dataset/lieux-culturels>

```{r}
#get data
data_parc <- read.csv("espace_vert.csv")
data_es <- read.csv("terrain_sport_ext.csv")
data_lc <- read_excel("lieuxculturels.xls")


#Parcs
nb_arrond_parc <- (table(data_parc$GESTION))
dat_nb_parc <- data.frame(arrond = names(nb_arrond_parc), nb_parc = as.numeric(nb_arrond_parc))
dat_parc <- dat %>%
  select(dur, n_tot, rev, arrond) %>% 
  group_by(arrond) %>%
  summarise(dur = (sum(dur)))
dat_nb_parc$arrond <- tolower(gsub("\\s+", "", dat_nb_parc$arrond))
dat_nb_parc$arrond<-gsub("-", "", dat_nb_parc$arrond)
dat_parc$arrond <- tolower(gsub("\\s+", "", dat_parc$arrond))
dat_parc$arrond<-gsub("-", "", dat_parc$arrond)

df_parc <- merge(dat_parc, dat_nb_parc, by = "arrond", all.x = TRUE)
df_parc$nb_parc <- ifelse(is.na(df_parc$nb_parc), 0, df_parc$nb_parc)

#Espaces sportifs
nb_arrond_es <- table(data_es$ARROND)
dat_nb_es <- data.frame(arrond = names(nb_arrond_es), nb_es = as.numeric(nb_arrond_es))
dat_nb_es$arrond <- tolower(gsub("\\s+", "", dat_nb_es$arrond))
dat_nb_es$arrond<-gsub("-", "", dat_nb_es$arrond)

dat_es <- dat_parc
df_es <- merge(dat_es, dat_nb_es, by = "arrond", all.x = TRUE)

#Lieux culturels
nb_arrond_lc <- table(data_lc$Arrondissement)
dat_nb_lc <- data.frame(arrond = names(nb_arrond_lc), nb_lc = as.numeric(nb_arrond_lc))
dat_nb_lc$arrond <- tolower(gsub("\\s+", "", dat_nb_lc$arrond))
dat_nb_lc$arrond<-gsub("-", "", dat_nb_lc$arrond)
dat_nb_lc$arrond <- gsub("[-–]", "", dat_nb_lc$arrond)

dat_lc <- dat_parc
df_lc <- merge(dat_lc, dat_nb_lc, by = "arrond", all.x = TRUE)


#Modèles vs rev
df_parc_es <- merge(df_parc, dat_nb_es, by = "arrond", all.x = TRUE)
df_parc_es_lc <- merge(df_parc_es, dat_nb_lc, by = "arrond", all.x = TRUE)
df_parc_es_lc <- replace(df_parc_es_lc, is.na(df_parc_es_lc), 0)

modele4 = lm(dur~nb_parc + nb_es + nb_lc, data = df_parc_es_lc)

```

# Modèle avec les festivals

Dans cette section, nous allons analyser si les festivals tenus dans la ville de Montréal ont un impact sur l'utilisation des Bixi. Cette question est intéressante, car elle permet, selon les résultats obtenus, de s'allier avec la ville de Montréal et différente organisations et organismes en lien avec les festivals pour promouvoir un moyen de déplacement moins intensif sur les émission de polluants. Plusieur stratégies d'affaires peuvent être pris selon les résultats. Par exemple : offrir des promotions dans les stations proches des festivals, augmenter la disponibilité des Bixi lors des festivals ou encore promouvoir le service à l'approche des différents festivals.

Pour tester cette question, nous allons produire plusieurs modèles de régression linéaire et faire de l'inférence sur les résultats obtenus. Les données des festivals viennent d'une archive disponible sur ce site web : <https://web.archive.org/web/20210928074344/https://www.mtl.org/fr/experience/guide-des-festivals-dete-montreal> et elles ont été compilées manuellement.

## Modèle linéaire simple

```{r fest1, out.height = "30%"}
mod_fest_1 = lm(n_tot_mod ~ festival, data = dat_mod)
summary(mod_fest_1)
```

Avec un modèle linéaire simple, la tenue de festival semble avoir un effet positif et significatif sur le nombre total de déplacements. En effet, un festival de plus par jour augmente en moyenne le nombre total de déplacement de 3.4% par jour par arrondissement (toutes choses étant égales par ailleurs). De plus, cette augmentation est significatif à un niveau de 95%.

Or, il est important de discuter des limitations d'un tel modèle. Plusieurs autres variables agissent sur le nombre total de déplacements et sur la tenue de festival, il faut ainsi controler pour ces variables. Pour mieux comprendre ce problème, voici un graphe orienté acyclique (GOA) \@ref(fig:firstgroup).

```{=tex}
\begin{figure}[h!]
\caption{\label{fig:firstgroup}}
\centering
\begin{tikzpicture}[->]
\node (X) at (0,0) {$festival$};
\node (Z2) at (1.5,-1) {$Z_1$};
\node (Y) at (3,0) {$n\_tot$};
\path (X) edge (Y);
\path (Z2) edge (X);
\path (Z2) edge (Y);
\end{tikzpicture}
\end{figure}
```
Ainsi, s'il existe des variables $Z_1$ qui affectent à la fois `festival` et `n_tot`, il faut ajouter ces variables dans le modèle pour avoir une estimation plus précises des effets des prédicteurs.

Au niveau de la normalité des résidus, on doit les analyser après la transformation logarithmique.

```{r fest-res1, out.height = "30%", fig.align='center', fig.cap="Distribution des résidus"}
resid <- rstudent(mod_fest_1)
fitted <- mod_fest_1$fitted.values
res.dat <- cbind(dat_mod, fitted, resid)
ggplot(data = res.dat, mapping = aes(x = resid)) + geom_density() +
geom_histogram(aes(y = ..density..), bins = 10, alpha = 0.5) +
xlab("Résidus") +
ylab("Densité")
```

```{r fest-qq1, out.height = "30%", fig.align='center', fig.cap="QQ-Plot Résidus Student"}
ggplot(data = res.dat, mapping = aes(sample = resid)) + stat_qq(distribution = qt,
dparams = mod_fest_1$df.residua) + stat_qq_line(distribution = qt,
dparams = mod_fest_1$df.residual) + labs(x = "Quantiles théoriques",
y = "Quantiles empiriques")
```

En observant les figures \@ref(fig:fest-res1) et \@ref(fig:fest-qq1), on voit que les résidus semblent ne pas être normales dans le premier tiers des données. Par la suite, les résidus semblent se rapprocher d'un distribution normale. Or, étant donné que les résidus ne sont pas parfaitement normales, cela va poser des limitations dans l'analyse et l'inférence des résultats.

## Modèle linéaire ajusté

Comme expliqué précédemment, nous devons ajouter des variables dans le modèles pour avoir une estimation plus précise. Il serait utile d'ajouter la variable `holiday`, `mm` et `wkend`. En effet, ces variables agissent à la fois sur `festival` et `n_tot`.

```{r, out.height = "30%"}
mod_fest_2 = lm(n_tot_mod ~ festival + mm + holiday + wkend, data = dat_mod)
summary(mod_fest_2)
```

En controlant pour les variables omises, nous observons maintenant un changement dans l'interprétation des résultats. L'effet des festival semble être négatif et non-significatif. Dans ce modèle, chaque festival diminue le nombre total de déplacement de 2,4% par jour par quartier de façon non-significative. Il semblerait que l'effet passe maintenant par les mois et non par les festivals.

Si nous analysons rapidement les résidus, nous voyons dans les figures \@ref(fig:fest-res2) et \@ref(fig:fest-qq2) qu'ils semblent légèrement plus normales que dans le premier modèle.

```{r fest-res2, out.height = "30%", fig.align='center', fig.cap="Distribution des résidus"}
resid <- rstudent(mod_fest_2)
fitted <- mod_fest_1$fitted.values
res.dat <- cbind(dat_mod, fitted, resid)
ggplot(data = res.dat, mapping = aes(x = resid)) + geom_density() +
geom_histogram(aes(y = ..density..), bins = 10, alpha = 0.5) +
xlab("Résidus") +
ylab("Densité")
```

```{r fest-qq2, out.height = "30%", fig.align='center', fig.cap="QQ-Plot Résidus Student"}
ggplot(data = res.dat, mapping = aes(sample = resid)) + stat_qq(distribution = qt,
dparams = mod_fest_2$df.residua) + stat_qq_line(distribution = qt,
dparams = mod_fest_2$df.residual) + labs(x = "Quantiles théoriques",
y = "Quantiles empiriques")
```

### Modèle avec interaction

Il peut être intéressant de tester un modèle avec interactions étant donné que les utilisations seront peut-être augmenté si un festival est pendant une fin de semaine ou une journée férié.

```{r}
mod_fest_3 = lm(n_tot_mod ~ festival*holiday +festival*wkend +festival + mm + holiday + wkend, data = dat_mod)
summary(mod_fest_3)
```

Or, il ne semble pas avoir d'effets non plus.

### Modèle avec seulement les non-membres

Il serait aussi intéressant de tester si les non-membres (qui ont une utilisation différente des Bixi) utilisent plus les Bixi lors des festivals. Pour cela, nous allons tester le deuxième modèle sur les non-membres seulement.

```{r, out.height = "30%"}
mod_fest_4 = lm(n_tot_mod ~ festival + mm + holiday + wkend, data = dat_mod[dat_mod$mem == 0,])
summary(mod_fest_4)
```

De façon similaire au modèle précédemment, les festivals n'ont pas d'effets significatifs même lorsqu'on regarde seulement les non-membres de Bixi.

## Discussion sur les résultats

Étant donné les résultats des modèles que nous avons fait précédemment, les festivals ne semblent pas avoir d'effets significatifs sur l'utilisation des Bixi que cela soit pour les membres ou les non-membres. Ainsi, nous ne pouvons pas nous prononcer sur des politiques et stratégies que l'entreprise pourrait appliquer.

# Modèles avec la densité de population

Dans cette section, il sera question de modéliser l’effet de la densité de la population par $km^2$ par arrondissement, sur le nombre total de déplacements en Bixi par arrondissement. Autrement dit, on essaye d’observer qu’est-ce qui arrive au nombre de totaux de déplacement si la densité de population augmente. À première vue, il est cohérent d’affirmer que si la densité de la population augmente, le nombre de déplacement à bicyclette augmentera aussi. Cette prémisse repose sur l'idée qu’une densité de population plus élevée favorise généralement la mise en place d'infrastructures favorables aux déplacements à bicyclette.

Pour Bixi ce type d’information devient alors crucial, d’une part puisque dans les zones à forte densité de population, les habitants ont souvent plus d'options de transport, ce qui peut réduire leur dépendance à la voiture favorisant ainsi l’utilisation des transports durable comme le vélo. D’autre part, les zones fortement densifiées ont généralement une plus grande concentration de commerce, de services publics et d’emploi à moindre distance. Cette proximité des destinations encourage alors l'utilisation de modes de transport adaptés aux déplacements courts, tels que le vélo. C’est pour ces raisons que nous pensons que la densité de la population est un excellent facteur à observer pour Bixi. 


```{r initialisation des données, include=FALSE}
library(stringr)
dat_pop <- read.csv("pop_arrondissement.csv")

dat_pop$Superficie <- gsub(",", ".", dat_pop$Superficie)
dat_pop$Superficie <- as.numeric(dat_pop$Superficie)

dat_pop$Population.2021. <- str_replace_all(dat_pop$Population.2021., "\\s", "")
dat_pop$Population.2021. <- as.numeric(dat_pop$Population.2021.)


dat_pop <- dat_pop %>% 
  rename(
    arrond = Nom,
    superficie = Superficie,
    population_2021 = Population.2021.
  )
dat_pop$density <- dat_pop$population_2021/dat_pop$superficie

dat_mod$arrond <- str_replace_all(dat_mod$arrond, " - ", "-")
dat_pop$arrond <- str_replace_all(dat_pop$arrond, "–", "-")

df_lieux_mtl <- read.csv("lieux-fr_MTL.csv")
df_lieux_long <- read.csv("vdq-lieupublic_longeuil.csv")
df_lieux_la <- read.csv("lieux_laval.csv")


df_lieux_la$type.commun <- as.factor(df_lieux_la$type.commun)
df_lieux_mtl$installations <- as.factor(df_lieux_mtl$installations)
df_lieux_long$DESCRIPTION <- as.factor(df_lieux_long$DESCRIPTION)

unique(df_lieux_long$DESCRIPTION)
unique(df_lieux_mtl$installations)
unique(df_lieux_la$type.commun)

intersect(df_lieux_la$type.commun, df_lieux_mtl$installations)

df_lieux_la$type.commun <- str_replace(df_lieux_la$type.commun, "Parcs linéaires|Parcs écoles", "Parc")

df_lieux_la <- subset(df_lieux_la, type.commun %in% c("Parc",
                                                      "Bibliothèque",
                                                      "Centre communautaire",
                                                      "Centre sportif"))

category_counts <- table(df_lieux_la$type.commun)

# Creation du DF pour Laval 
df_lieux_la <- data.frame(
  Category = c("Parc",
  "Bibliotheque",
  "Centre_communautaire",
  "Centre_sportif"),
  Count = c(category_counts["Parc"],
            category_counts["Bibliothèque"],
            category_counts["Centre communautaire"],
            category_counts["Centre sportif"])
)
df_lieux_la <- pivot_wider(df_lieux_la, names_from = Category, values_from = Count)
df_lieux_la$arrond <- "Laval"

# Création du DF pour mtl. 
df_lieux_mtl <- df_lieux_mtl %>%
  filter(installations %in% c("Parc","Bibliothèque","Centre communautaire","Centre sportif")) %>%
  group_by(arrondissements) %>%
  summarize(
    Parc = sum(installations == "Parc"),
    Bibliotheque = sum(installations == "Bibliothèque"),
    Centre_communautaire=sum(installations == "Centre communautaire"),
    Centre_sportif=sum(installations == "Centre sportif")
  )

df_lieux_mtl$arrond <- df_lieux_mtl$arrondissements
df_lieux_mtl <- df_lieux_mtl[2:6]

# Création du DF pour longeuil 
df_lieux_long$DESCRIPTION <- str_replace(df_lieux_long$DESCRIPTION, "Parcs écoles", "Parc")
category_counts <- table(df_lieux_long$DESCRIPTION)

df_lieux_long <- data.frame(
  Category = c("Parc",
  "Bibliotheque",
  "Centre_communautaire",
  "Centre_sportif"),
  Count = c(category_counts["Parc"],
            category_counts["Bibliothèques"],
            category_counts["Centres communautaires"],
            category_counts["Centres sportifs"])
)

df_lieux_long <- pivot_wider(df_lieux_long, names_from = Category, values_from = Count)
df_lieux_long$arrond <- "Longueuil"

df_la_long <- rbind(df_lieux_long,df_lieux_la)

# Ces données ne sont pas disponible sous forme CSV, mais sont dispoible sur le site web des villes 
df_Westmont_MR <- data.frame(
  Parc=c(12,22),
  Bibliotheque=c(1,1),
  Centre_communautaire=c(20,19),
  Centre_sportif=c(1,2),
  arrond=c("Westmount","Mont-Royal")
)

df_la_long<- rbind(df_la_long,df_Westmont_MR)

df_rmr <- rbind(df_la_long,df_lieux_mtl)

df_rmr$arrond <- str_replace_all(df_rmr$arrond, " - ", "-")
df_rmr$arrond <- str_replace_all(df_rmr$arrond, "–", "-") 


setdiff(dat_mod$arrond, df_rmr$arrond)

df_rmr<- dat_pop %>% left_join(df_rmr, by="arrond")

# Division des parc, biblio et les centres par la superficie. Permet de standardisé selon la grandeur du territoire
df_rmr <- df_rmr %>%
  mutate(
    ParcKm2 = Parc / superficie,
    BibliothequeKm2 = Bibliotheque / superficie,
    Centre_communautaireKm2 = Centre_communautaire / superficie,
    Centre_sportifKm2 = Centre_sportif / superficie
  )


dat_mod<- dat_mod %>% left_join(df_rmr, by="arrond")



```

## Modèle linéaire simple

```{r SimpleDensity}

options(scipen=999)

model_density <- lm(n_tot~density ,dat_mod )

summary(model_density)
```

Dans ce modèle de régression linéaire simple, il est possible de constater que la variable de densité est bien significative. Autrement dit, une augmentation d'une personne par kilomètre carré augmenterait en moyenne le nombre total de déplacements de 0.012. Cependant, la valeur du $R^2$ signifie que le modèle explique 19,17% de la variabilité du nombre total de déplacements. Cela dit, il y a nécessairement un manque de variables explicatives qui permettrait de mieux expliquer la variable réponse.

Avant d'amorcer un modèle multiple, il est crutial d'observer si l'hypothèse d'homoscédasticité est respectées dans ce modèle simple.

```{r QQdensite, out.height = "30%", fig.align = 'center', fig.cap = "Graphique QQ - modèle de densité démographique simple"}


residuals <- residuals(model_density)


ggplot(data.frame(Résidus = residuals), aes(sample = Résidus)) +
  stat_qq() +
  stat_qq_line() +
  xlab("Quantiles Théoriques") +
  ylab("Quantiles de l'Échantillon") +
  ggtitle("Graphique Q-Q")

```

En examinant le comportement des résidus dans la figure \@ref(fig:QQdensite), il est plausible de dire que dans le dernier tier de la figure les résidus ne suivent pas une loi normale. Cela étant dit, dans le cas de ce modèle simple ça voudrait dire que la densité comme seule variable explicative explique mal le comportement du nombre total de déplacements en Bixi.

*À VOIR SI JE LAISSE*

```{r}
dat_mod$logDensity<- log(dat_mod$density)
dat_mod$logN_tot <- log(dat_mod$n_tot)

model_log_density <- lm(logN_tot~logDensity,dat_mod)
summary(model_log_density)

residuals <- residuals(model_log_density)

ggplot(data.frame(Résidus = residuals), aes(sample = Résidus)) +
  stat_qq() +
  stat_qq_line() +
  xlab("Quantiles Théoriques") +
  ylab("Quantiles de l'Échantillon") +
  ggtitle("Graphique Q-Q")

```

## Régression multiple

Avant de débuter le modèle multiple avec la densité de population, il est important de comprendre que plusieurs données ont été ajoutées et même modifier pour pouvoir observer la tendance que prend l'utilisation des Bixis lorsque la densité de population augmente. Cela étant dit, il était important d'ajouter des variables qui affectaient autant la densité de population que le nombre total de Bixi utilisé, comme expliqué dans la figure \@ref(fig:firstgroup). Par conséquent, des variables comme le nombre de parcs par arrondissement, le nombre de bibliothèques par arrondissement, le nombre de centres communautaire par arrondissement et le nombre de centres sportifs par arrondissement ont été ajoutés. De plus, puisque la superficie des arrondissements varie grandement, ces variables ajoutées ont été divisées par la superficie de chaque arrondissement. Ainsi les grandes villes, comme Laval qui a beaucoup d'infrastructure à cause de sa grande superficie, ne viendront pas biaiser nos modèles. Autrement dit, les variables ajoutées(nombre de parcs, le nombre de bibliothèques, le nombre de centres communautaires, le nombre de centres sportifs) sont par $km^2$ de leur arrondissement.

```{r}
model_desity_M <- lm(formula = n_tot ~ density + ParcKm2 + BibliothequeKm2 + Centre_communautaireKm2 + Centre_sportifKm2, data = dat_mod)

summary(model_desity_M)

```

```{r}
residuals <- residuals(model_desity_M)

ggplot(data.frame(Résidus = residuals), aes(sample = Résidus)) +
  stat_qq() +
  stat_qq_line() +
  xlab("Quantiles Théoriques") +
  ylab("Quantiles de l'Échantillon") +
  ggtitle("Graphique Q-Q")

```



# Conclusion
