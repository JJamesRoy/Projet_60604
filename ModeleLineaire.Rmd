---
title: "Projet BIXI - Partie 2: Modèle de régression linéaire"
subtitle: "MATH60604 - Modélisation statistique"
author: "Abdoul Wassi Badirou, Alfred Assal, James Roy, Samuel Croteau"
date: "`r Sys.Date()`"
output:
  # pdf_document:
  #   toc: yes
  #   toc_depth: '3'
  bookdown::html_document2:
    toc: yes
    number_sections: yes
    toc_float:
      collapsed: no
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 3
    extra_dependencies: flafter
params:
  created_date: "2023-09-12"
header-includes:
- \usepackage{tikz}
- \usepackage{subcaption}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message = FALSE,warning = FALSE,error = TRUE, fig.pos = "H")
```

```{r lib}
library(tidyverse)
library(readxl)
library(knitr)
library(googleway)
```

# Note

Question : Comment maximiser les déplacements en Bixi pour accélérer la transition vers une économie verte et réduire l'impact sur l'environnement des moyens de transports.

Sous question :  
- Impact de l'événementiel (James)

- Est-ce que la densité de population du quartier a un impact sur l'utilisation des Bixi (Alfred)

- Attraits touristiques (https://donnees.montreal.ca/dataset/installations-recreatives-sportives-et-culturelles/resource/1c239e86-8b36-476c-bd51-91a3cd20f687) (https://donnees.montreal.ca/dataset/lieux-d-interet/resource/edce22aa-f7cc-495e-9c53-b367f68309f6) (Abdoul)

- Parc (https://donnees.montreal.ca/dataset/grands-parcs-parcs-d-arrondissements-et-espaces-publics) (Sam)


Leviers de Bixi : Publicité et marketing sur le service et l'abonnement. Programme incitation Bixi (alléger les stations ou remplir)

Variables cibles : n_tot et dur

Variables à ajouter : merge avec les autres données par sous-question


```{r read}
dat = read.csv("bixifull.csv")
```

```{r festival}
festivals <- data.frame(
  Start_Date = as.Date(c("2021-05-10", "2021-05-22", "2021-05-27", "2021-06-06", "2021-06-07",
                         "2021-06-07", "2021-06-07", "2021-06-11", "2021-06-13", "2021-06-14",
                         "2021-06-20", "2021-06-26", "2021-06-27", "2021-06-29", "2021-07-04",
                         "2021-07-05", "2021-07-06", "2021-07-09", "2021-07-10",
                         "2021-07-11", "2021-07-11", "2021-07-22", "2021-07-27", "2021-07-28",
                         "2021-08-02", "2021-08-06", "2021-08-07", "2021-08-08", "2021-08-09",
                         "2021-08-09", "2021-08-19", "2021-08-20", "2021-08-29", "2021-08-30")),
  End_Date = as.Date(c("2021-05-17", "2021-06-04", "2021-06-16", "2021-06-16", "2021-06-09",
                       "2021-06-16", "2021-06-09", "2021-06-16", "2021-06-16", "2021-06-22",
                       "2021-06-23", "2021-06-30", "2021-07-06", "2021-07-27", "2021-07-14",
                       "2021-07-07", "2021-07-06", "2021-07-14", "2021-07-21", "2021-07-28",
                       "2021-07-27", "2021-08-01", "2021-07-28", "2021-07-28", "2021-08-04",
                       "2021-08-14", "2021-08-11", "2021-08-18", "2021-08-10", "2021-08-18",
                       "2021-08-24", "2021-08-25", "2021-09-02", "2021-09-02"))
)

dates <- festivals %>%
  rowwise() %>%
  mutate(Date = list(seq(Start_Date, End_Date, by = "day"))) %>%
  unnest(Date)

result_df <- dates %>%
  group_by(Date) %>%
  summarize(festival = n())

dat$Date <- as.Date(paste("2021", dat$mm, dat$dd, sep = "-"))

dat <- dat %>%
  left_join(result_df, by = "Date")

dat$festival[is.na(dat$festival)] = 0
```

```{r rain}
dat = dat %>% mutate(rain_bin = ifelse(rain == 0, 0, 1)) %>% select(-X)
```

```{r wkend}
dat = dat %>% mutate(wkend = ifelse(wday == "Saturday" | wday == "Sunday",1,0))
col = c("mm", "dd", "mem", "arrond")
dat[col] = lapply(dat[col], factor)
```

```{r dat.mod}
var_mean= c("holiday", "temp", "rain", "festival", "rain_bin", "wkend")
var_sum = c("dur", "rev", "n_tot", "n_AM", "n_PM", "avg")

dat_mod = dat %>% select(-station, -name, -wday, -Date) %>% 
  group_by(mem, mm, dd, arrond) %>%
  summarise(across(all_of(var_mean), ~mean(., na.rm = TRUE)),
            across(all_of(var_sum), ~sum(., na.rm = TRUE))) # Sert à compiler les données selon les arrondissements par jour. On se débarasse ainsi des variables station. Cela fait qu'on peut analyser les données par arrondissement plutot que par station.

dat_mod = as.data.frame(dat_mod)

col = c("holiday", "wkend", "rain_bin")
dat_mod[col] = lapply(dat_mod[col], factor)
```

# Enrichissement des données {.unnumbered}
```{r importData, results='hide'}
bixi_raw_data_df = read.csv("bixi1.csv", sep=",", header = T)
head(bixi_raw_data_df)
```
```{r importMergeStationNameAndCoord, results='hide'}
# Importation des données de stations: Nom, latitude et Longitude
stations_raw_data_df=read.csv("2021_stations.csv", sep = ",", header = T, encoding='latin_1')
head(stations_raw_data_df)

#Jointure aux données bixi
bixi_with_name_df=merge(bixi_raw_data_df,stations_raw_data_df, by.x = "station",by.y = "pk", all.x = T, all.y = F)
head(bixi_with_name_df)
str(bixi_with_name_df)
```
```{r , results='hide'}
# Validons qu'il n'y a pas de données manquantes suite à l'ajout des noms des stations et leur coordonnées géographique
summary(bixi_with_name_df)
```
```{r, results='hide'}
#Importation des données de stations: Nom, arrondissement, latitude, longitude
bixi_stations_df=read.csv("bixi_stations_full.csv", sep = ",", header = T, encoding='latin_1')
head(bixi_stations_df)

# merge pour inclure les arrondissements
bixi_with_arrond_df=merge(bixi_with_name_df,bixi_stations_df, by.x = 'name',by.y = 'STATIONNAME', all.x = T, all.y = F)
head(bixi_with_arrond_df)
```
```{r}
summary(bixi_with_arrond_df)
```
```{r}
bixiWithArron_clean_df=data.frame(name=bixi_with_arrond_df$name,latitude=bixi_with_arrond_df$latitude,
      longitude=bixi_with_arrond_df$longitude,arrondissement=bixi_with_arrond_df$STATIONARRONDISSEMENT,
      bixi_with_arrond_df[,names(bixi_raw_data_df)])
```



# Introduction
- Déterminer les éléments qui influencent l'utilisation des bixi (nombre de déplacement) afin de proposer des stratégies qui permettraient de mieux la démocratiser.

- Déterminer le prix d'imputation des usagers membres qui permettrait de générer un revenu équivalent à celui des non-membres.

# Transformation variables d'intérêts

Nous allons observer nos variables d'intérêts pour voir si elles se prêtent à l'analyse statistique.

```{r histn, out.height = "30%", fig.cap="Distribution des déplacements totaux", fig.align='center'}
hist(dat_mod$n_tot, 
     ylab = "Fréquence", 
     xlab = "Nombre de déplacement totaux",
     main = "")
```

Dans la \@ref(fig:histn), on voit que les données de la variable `n_tot` ne sont pas normales, il faudrait les normaliser pour être capable de faire des analyses statistiques à l'aide de régression linéaire.

```{r histn2, out.height = "30%", fig.cap="Distribution du log des déplacements totaux", fig.align='center'}
dat_mod = dat_mod %>% mutate(n_tot_mod = log(n_tot))
hist(dat_mod$n_tot_mo, 
     ylab = "Fréquence", 
     xlab = "Nombre de déplacement totaux",
     main = "")
```

Maintenant, dans la \@ref(fig:histn2), on voit qu'avec une transformation logarithmique, les données se normalisent. Par contre, le côté gauche de la courbe est encore relevé, cela peut impacter l'inférence statistique que nous allons faire prochainement.

# Analyse de multicolinéarité
À faire si on a le temps.

# Parc

Données utilisées: <https://donnees.montreal.ca/dataset/installations-recreatives-sportives-et-culturelles/resource/1c239e86-8b36-476c-bd51-91a3cd20f687> <https://donnees.montreal.ca/dataset/grands-parcs-parcs-d-arrondissements-et-espaces-publics> <https://donnees.montreal.ca/dataset/lieux-culturels>

```{r}
#get data
data_parc <- read.csv("espace_vert.csv")
data_es <- read.csv("terrain_sport_ext.csv")
data_lc <- read_excel("lieuxculturels.xls")


#Parcs
nb_arrond_parc <- (table(data_parc$GESTION))
dat_nb_parc <- data.frame(arrond = names(nb_arrond_parc), nb_parc = as.numeric(nb_arrond_parc))
dat_parc <- dat %>%
  select(dur, n_tot, rev, arrond) %>% 
  group_by(arrond) %>%
  summarise(dur = (sum(dur)))
dat_nb_parc$arrond <- tolower(gsub("\\s+", "", dat_nb_parc$arrond))
dat_nb_parc$arrond<-gsub("-", "", dat_nb_parc$arrond)
dat_parc$arrond <- tolower(gsub("\\s+", "", dat_parc$arrond))
dat_parc$arrond<-gsub("-", "", dat_parc$arrond)

df_parc <- merge(dat_parc, dat_nb_parc, by = "arrond", all.x = TRUE)
df_parc$nb_parc <- ifelse(is.na(df_parc$nb_parc), 0, df_parc$nb_parc)

#Espaces sportifs
nb_arrond_es <- table(data_es$ARROND)
dat_nb_es <- data.frame(arrond = names(nb_arrond_es), nb_es = as.numeric(nb_arrond_es))
dat_nb_es$arrond <- tolower(gsub("\\s+", "", dat_nb_es$arrond))
dat_nb_es$arrond<-gsub("-", "", dat_nb_es$arrond)

dat_es <- dat_parc
df_es <- merge(dat_es, dat_nb_es, by = "arrond", all.x = TRUE)

#Lieux culturels
nb_arrond_lc <- table(data_lc$Arrondissement)
dat_nb_lc <- data.frame(arrond = names(nb_arrond_lc), nb_lc = as.numeric(nb_arrond_lc))
dat_nb_lc$arrond <- tolower(gsub("\\s+", "", dat_nb_lc$arrond))
dat_nb_lc$arrond<-gsub("-", "", dat_nb_lc$arrond)
dat_nb_lc$arrond <- gsub("[-–]", "", dat_nb_lc$arrond)

dat_lc <- dat_parc
df_lc <- merge(dat_lc, dat_nb_lc, by = "arrond", all.x = TRUE)


#Modèles vs rev
df_parc_es <- merge(df_parc, dat_nb_es, by = "arrond", all.x = TRUE)
df_parc_es_lc <- merge(df_parc_es, dat_nb_lc, by = "arrond", all.x = TRUE)
df_parc_es_lc <- replace(df_parc_es_lc, is.na(df_parc_es_lc), 0)

modele4 = lm(dur~nb_parc + nb_es + nb_lc, data = df_parc_es_lc)

```

# Modèle avec les festivals

Dans cette section, nous allons analyser si les festivals tenus dans la ville de Montréal ont un impact sur l'utilisation des Bixi. Cette question est intéressante, car elle permet, selon les résultats obtenus, de s'allier avec la ville de Montréal et différente organisations et organismes en lien avec les festivals pour promouvoir un moyen de déplacement moins intensif sur les émission de polluants. Plusieur stratégies d'affaires peuvent être pris selon les résultats. Par exemple : offrir des promotions dans les stations proches des festivals, augmenter la disponibilité des Bixi lors des festivals ou encore promouvoir le service à l'approche des différents festivals.

Pour tester cette question, nous allons produire plusieurs modèles de régression linéaire et faire de l'inférence sur les résultats obtenus. Les données des festivals viennent d'une archive disponible sur ce site web : <https://web.archive.org/web/20210928074344/https://www.mtl.org/fr/experience/guide-des-festivals-dete-montreal> et elles ont été compilées manuellement.

## Modèle linéaire simple

```{r fest1, out.height = "30%"}
mod_fest_1 = lm(n_tot_mod ~ festival, data = dat_mod)
summary(mod_fest_1)
```

Avec un modèle linéaire simple, la tenue de festival semble avoir un effet positif et significatif sur le nombre total de déplacements. En effet, un festival de plus par jour augmente en moyenne le nombre total de déplacement de 3.4% par jour par arrondissement (toutes choses étant égales par ailleurs). De plus, cette augmentation est significatif à un niveau de 95%.

Or, il est important de discuter des limitations d'un tel modèle. Plusieurs autres variables agissent sur le nombre total de déplacements et sur la tenue de festival, il faut ainsi controler pour ces variables. Pour mieux comprendre ce problème, voici un graphe orienté acyclique (GOA) \@ref(fig:firstgroup).

```{=tex}
\begin{figure}[h!]
\caption{\label{fig:firstgroup}}
\centering
\begin{tikzpicture}[->]
\node (X) at (0,0) {$festival$};
\node (Z2) at (1.5,-1) {$Z_1$};
\node (Y) at (3,0) {$n\_tot$};
\path (X) edge (Y);
\path (Z2) edge (X);
\path (Z2) edge (Y);
\end{tikzpicture}
\end{figure}
```
Ainsi, s'il existe des variables $Z_1$ qui affectent à la fois `festival` et `n_tot`, il faut ajouter ces variables dans le modèle pour avoir une estimation plus précises des effets des prédicteurs.

Au niveau de la normalité des résidus, on doit les analyser après la transformation logarithmique.

```{r fest-res1, out.height = "30%", fig.align='center', fig.cap="Distribution des résidus"}
resid <- rstudent(mod_fest_1)
fitted <- mod_fest_1$fitted.values
res.dat <- cbind(dat_mod, fitted, resid)
ggplot(data = res.dat, mapping = aes(x = resid)) + geom_density() +
geom_histogram(aes(y = ..density..), bins = 10, alpha = 0.5) +
xlab("Résidus") +
ylab("Densité")
```

```{r fest-qq1, out.height = "30%", fig.align='center', fig.cap="QQ-Plot Résidus Student"}
ggplot(data = res.dat, mapping = aes(sample = resid)) + stat_qq(distribution = qt,
dparams = mod_fest_1$df.residua) + stat_qq_line(distribution = qt,
dparams = mod_fest_1$df.residual) + labs(x = "Quantiles théoriques",
y = "Quantiles empiriques")
```

En observant les figures \@ref(fig:fest-res1) et \@ref(fig:fest-qq1), on voit que les résidus semblent ne pas être normales dans le premier tiers des données. Par la suite, les résidus semblent se rapprocher d'un distribution normale. Or, étant donné que les résidus ne sont pas parfaitement normales, cela va poser des limitations dans l'analyse et l'inférence des résultats.

## Modèle linéaire ajusté

Comme expliqué précédemment, nous devons ajouter des variables dans le modèles pour avoir une estimation plus précise. Il serait utile d'ajouter la variable `holiday`, `mm` et `wkend`. En effet, ces variables agissent à la fois sur `festival` et `n_tot`.

```{r, out.height = "30%"}
mod_fest_2 = lm(n_tot_mod ~ festival + mm + holiday + wkend, data = dat_mod)
summary(mod_fest_2)
```

En controlant pour les variables omises, nous observons maintenant un changement dans l'interprétation des résultats. L'effet des festival semble être négatif et non-significatif. Dans ce modèle, chaque festival diminue le nombre total de déplacement de 2,4% par jour par quartier de façon non-significative. Il semblerait que l'effet passe maintenant par les mois et non par les festivals.

Si nous analysons rapidement les résidus, nous voyons dans les figures \@ref(fig:fest-res2) et \@ref(fig:fest-qq2) qu'ils semblent légèrement plus normales que dans le premier modèle.

```{r fest-res2, out.height = "30%", fig.align='center', fig.cap="Distribution des résidus"}
resid <- rstudent(mod_fest_2)
fitted <- mod_fest_1$fitted.values
res.dat <- cbind(dat_mod, fitted, resid)
ggplot(data = res.dat, mapping = aes(x = resid)) + geom_density() +
geom_histogram(aes(y = ..density..), bins = 10, alpha = 0.5) +
xlab("Résidus") +
ylab("Densité")
```

```{r fest-qq2, out.height = "30%", fig.align='center', fig.cap="QQ-Plot Résidus Student"}
ggplot(data = res.dat, mapping = aes(sample = resid)) + stat_qq(distribution = qt,
dparams = mod_fest_2$df.residua) + stat_qq_line(distribution = qt,
dparams = mod_fest_2$df.residual) + labs(x = "Quantiles théoriques",
y = "Quantiles empiriques")
```

### Modèle avec interaction

Il peut être intéressant de tester un modèle avec interactions étant donné que les utilisations seront peut-être augmenté si un festival est pendant une fin de semaine ou une journée férié.

```{r}
mod_fest_3 = lm(n_tot_mod ~ festival*holiday +festival*wkend +festival + mm + holiday + wkend, data = dat_mod)
summary(mod_fest_3)
```

Or, il ne semble pas avoir d'effets non plus.

### Modèle avec seulement les non-membres

Il serait aussi intéressant de tester si les non-membres (qui ont une utilisation différente des Bixi) utilisent plus les Bixi lors des festivals. Pour cela, nous allons tester le deuxième modèle sur les non-membres seulement.

```{r, out.height = "30%"}
mod_fest_4 = lm(n_tot_mod ~ festival + mm + holiday + wkend, data = dat_mod[dat_mod$mem == 0,])
summary(mod_fest_4)
```

De façon similaire au modèle précédemment, les festivals n'ont pas d'effets significatifs même lorsqu'on regarde seulement les non-membres de Bixi.

## Discussion sur les résultats

Étant donné les résultats des modèles que nous avons fait précédemment, les festivals ne semblent pas avoir d'effets significatifs sur l'utilisation des Bixi que cela soit pour les membres ou les non-membres. Ainsi, nous ne pouvons pas nous prononcer sur des politiques et stratégies que l'entreprise pourrait appliquer.

# Modèles avec la densité

```{r initialisation des données}
library(stringr)
dat_pop <- read.csv("pop_arrondissement.csv")

dat_pop$Superficie <- gsub(",", ".", dat_pop$Superficie)
dat_pop$Superficie <- as.numeric(dat_pop$Superficie)

dat_pop$Population.2021. <- str_replace_all(dat_pop$Population.2021., "\\s", "")
dat_pop$Population.2021. <- as.numeric(dat_pop$Population.2021.)


dat_pop <- dat_pop %>% 
  rename(
    arrond = Nom,
    superficie = Superficie,
    population_2021 = Population.2021.
  )
dat_pop$density <- dat_pop$population_2021/dat_pop$superficie

dat$arrond <- str_replace_all(dat$arrond, " - ", "-")

arrond = c(
    "Villeray-Saint-Michel-Parc-Extension",
    "Ville-Marie",
    "Verdun",
    "Saint-Léonard",
    "Saint-Laurent",
    "Rosemont-La Petite-Patrie",
    "Rivière-des-Prairies-Pointe-aux-Trembles",
    "Pierrefonds-Roxboro",
    "Outremont",
    "Montréal-Nord",
    "Mercier-Hochelaga-Maisonneuve",
    "L'Île-Bizard–Sainte-Geneviève",
    "Le Sud-Ouest",
    "Le Plateau-Mont-Royal",
    "LaSalle",
    "Lachine",
    "Côte-des-Neiges-Notre-Dame-de-Grâce",
    "Anjou",
    "Ahuntsic-Cartierville",
    "Westmount",
    "Mont-Royal",
    "Laval",
    "Longueuil"
  )
dat_pop$arrond <- arrond

dat<- dat %>% left_join(dat_pop)

unique(dat$arrond[is.na(dat$population_2021)])

```

## Modèle linéaire simple

```{r SimpleDensity}

model_density <- lm(n_tot~density ,dat )

summary(model_density)
```

Dans ce modèle de régression linéaire simple, il est possible de constater que la variable de densité est bien significative. Autrement dit, une augmentation d'une personne par kilomètre carré augmenterait en moyenne le nombre total de déplacements de 0.0024. Cependant, la valeur du $R^2$ signifie que le modèle explique 9,4% de la variabilité du nombre total de déplacements. Cela dit, il y a nécessairement un manque de variables explicatives qui permettrait de mieux expliquer la variable réponse.

Dans ce même ordre d'idée, il est possible d'observer si l'hypothèse de normalité des résidus ainsi que l'hypothèse d'homoscédasticité sont respectées dans ce modèle simple, avant d'amorcer un modèle multiple.

```{r QQdensite,out.height = "30%", fig.align='center', fig.cap= Graphique QQ - modèle de densité démogrphaique simple}


residuals <- residuals(model_density)


ggplot(data.frame(Résidus = residuals), aes(sample = Résidus)) +
  stat_qq() +
  stat_qq_line() +
  xlab("Quantiles Théoriques") +
  ylab("Quantiles de l'Échantillon") +
  ggtitle("Graphique Q-Q")



```

En examinant le comportement des résidus dans la figure \@ref(fig:QQdensite), il est plausible de dire que les résidus ne suivent pas une loi normale. Cela étant dit, dans le cas de ce modèle simple cela veut dire que la densité comme seule variable explicative explique mal le comportement du nombre total de déplacements en Bixi.


# Conclusion
