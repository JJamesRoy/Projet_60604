---
title: "Projet BIXI - Partie 3: Modèle linéaire généralisés"
subtitle: "MATH60604 - Modélisation statistique"
author: "Abdoul Wassi Badirou, Alfred Assal, James Roy, Samuel Croteau"
date: "`r Sys.Date()`"
geometry: margin=1.5cm
output:
  # bookdown::html_document2:
  #   toc: yes
  #   number_sections: yes
  #   toc_float:
  #     collapsed: no
  # #   toc_depth: '3'
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 1
    extra_dependencies: ["flafter"]
params:
  created_date: "2023-09-12"
header-includes:
#- \usepackage{tikz}
#- \usepackage{subcaption}
#- \usepackage{graphicx}
#- \usepackage{sidecap}
- \usepackage{float}
- \usepackage{amsmath}
- \usepackage{ragged2e}
#- \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message = FALSE,warning = FALSE,error = TRUE, fig.pos = "H")
```

```{r lib}
library(tidyverse)
library(readxl)
library(knitr)
library(googleway)
library(ggplot2)
library(car)
library(cleandata)
library(data.table)
library(kableExtra)
library(gridExtra)
library(jtools)
library(descr)
library(MASS)
library(emmeans)
```

```{r read}
dat = read.csv("bixifull.csv")
dat_full = read.csv("bixi_arrond_dens_full.csv") # Dataset avec les données sur les arrondissement, densité, etc...
dat_full$arrond <- factor(dat_full$arrond)
#hist(dat$n_tot)
#hist(dat$n_PM)
#hist(dat$n_AM)
```

```{r}
dat_full = dat_full %>% mutate(u15 = ifelse(avg > 15,1,0))
```

```{r}
dat_full <- dat_full %>%
  group_by(arrond) %>%
  mutate(nb_stations = n_distinct(station)) %>% 
  mutate(station_density = nb_stations/superficie)
```

# Introduction

Dans cette troisième partie du projet, nous allons explorer des modèles linéaires généralisés pour expliquer le nombre de déplacements dans les stations Bixi, de même que les déplacements de plus ou moins 15 minutes. En effet, comprendre l'utilisation des Bixi permettrait d'alimenter des plans stratégiques d'expansion des activités à travers le territoire et par ricochet l'accroissement du portefeuille de clients. Cette compréhension peut servir de base également à des plans tactiques qui viseraient à déterminer le meilleur moment pour l'entretien de la flotte de Bixi.

Ainsi nos travaux sont segmentés en deux volets principaux. Le premier sur la compréhension des voyages de plus ou moins 15 minutes et le deuxième sur l'achalandage. Dans ce dernier, nous explorons les modèles sur le nombre de déplacements en matinée, en après-midi et toute la journée. Dans chacun de ces modèles nous définissons le meilleur modèle qui nous permet d'avoir une interprétation le plus réaliste possible, puis nous tirons des conclusions d'un point de vue d'affaire avant de discuter des limites de nos analyses.

# Modèles sur les voyages de plus ou moins 15 minutes

L'entreprise est confronté à un problème de disponibilités dans certains arrondissements, dans certaines stations ils ne restent plus de Bixi pour les autres usagers. Elle croit que cela peut être du à des utilisateurs qui font des voyages trop long (plus de 15 minutes) et donc monopolisent les Bixi pour eux. En l'absence de variables sur la disponibilités, nous proposons d'utiliser une variable binaire `u15` qui prend la valeur de 1 si la durée moyenne à partir d'une certaine station à une certaine journée de l'année est supérieure à 15 minutes, 0 sinon. Bien que cette variable est imparfaite, il sera possible de cibler certaines conditions spécifiques (comme les arrondissements, les mois de l'année, etc.) qui agissent sur la disponibilité des Bixi.

```{r plot-u15, out.height = "22%", fig.align='center', fig.cap="Distribution de u15"}
barplot(table(dat_full$u15), col = c("red", "blue"), main = "", xlab = "Valeurs", ylab = "Fréquence")
```

Comme il est possible de le voir dans le graphique \@ref(fig:plot-u15), la variable cible est binaire, il faut ainsi faire une régression généralisée *logit.*

## Effets des arrondissements sur la variable `u15`

```{r}
pop <- dat_full %>%
  group_by(arrond) %>%
  summarise(dens = mean(density, na.rm = TRUE),
            dens_stat = mean(station_density))
```

### Modèles

Il est possible d'ajuster un modèle simple pour voir les effets des différents arrondissements sur la probabilité d'avoir des stations où le déplacement moyen est supérieur à 15 minutes afin de trouver les arrondssements plus problématiques. Nous allons ajuster ce modèle :

$$u15_i = B_0 + \sum_{j \epsilon Ns}B_jarrond_{i} + e_i$$ Où $j$ est un arrondissement dans la liste des arrondissements $N_s$.

```{r, out.height = "10%"}
dat_full$arrond <- relevel(dat_full$arrond, ref = "Le Plateau-Mont-Royal")
mod_u15_1 = glm(u15 ~ arrond, data = dat_full, family = binomial(link = "logit"))
#summary(mod_u15_1)
summ(mod_u15_1, model.info = FALSE)
```

Avant d'interpréter ce modèle, nous allons voir s'il est possible d'ajuster un modèle plus juste et plus complet.

```{r}
prob_lachine = round((exp(-1.22293+2.80111)/(1+exp(-1.22293+2.80111)))*100, digits = 1)
```

\

```{=html}
<!---Selon ce premier modèle, on voit que comparé à l'arrondissement du Plateau-Mont-Royal, les déplacements faits dans tous les autres arrondissements et villes ont plus de chances d'être plus long que 15 minutes en moyennes. Cette observations est significative pour un niveau de significativité de 1%.

Par exemple, la probabilité que la moyenne des voyages soit de plus de 15 minutes à une station dans l'arrondissement Lachine est de `r prob_lachine`%. En comparaison au Plateau Mont-Royal, la quote que la moyenne des voyages est de 2,80, c'est-à-dire...--->
```
Maintenant, nous pouvons ajuster un modèle plus complexe pour voir s'il est possible de raffiner l'analyse et obtenir un modèle plus juste. Le modèle à ajuster sera :

$$u15_i = B_0 + \sum_{j \epsilon N_s}B_jarrond_{i} + B_2mem_i + \sum_{m \epsilon M}B_mmm_{i} + B_3wkend_i + B_4rain\_bin_i + e_i$$

```{r, out.height = "10%"}
mod_u15_2 = glm(u15 ~ arrond + mem + as.factor(mm) + wkend + rain_bin, data = dat_full, family = binomial(link = "logit"))
summ(mod_u15_2, model.info = FALSE)
```

Nous allons d'abord comparer le modèle avec le précédent avant de l'interpréter, car il se peut que le premier modèle soit une simplifcation correcte du deuxième modèle. C'est-à-dire que les deux modèles ne sont pas significativement différent en terme de qualité d'ajustement.

Nous allons donc faire le test suivant :

$H_0$ : Les modèles sont équivalents, soit $B_2=\sum_{m \epsilon M}B_m=B_3=B_4 = 0$

$H_1$ : Les modèles ne sont pas équivalents, donc l'ajout des nouvelles variables améliorent significativement l'ajustement du modèle, soit un des $B$ ci-haut $\neq 0$.

```{r}
anova(mod_u15_1, mod_u15_2, test = "Chisq")
```

Ainsi, nous voyons que la valeur-P associée au test ci-dessus est inférieure à 0.1%, donc nous pouvons rejeter l'hypothèse nulle. En conclusion, un des $B$ ci-haut $\neq 0$, donc on peut continuer et interpréter le 2e modèle.

De plus, selon les critères AIC et BIC, le deuxième modèle minimise ces critères (AIC : 11794 \< 12825 et BIC : 12011 \< 12969). Ainsi, cela rejoint la conclusion faite pour le test ci-dessus.

Dans ce cas, nous allons interpréter les résultats pour pouvoir dégager des informations pertinentes et stratégiques pour l'entreprise Bixi.

```{r tab-top}
top_arrondissements <- dat_full %>%
  group_by(arrond) %>%
  summarise(nb_stations = mean(nb_stations, na.rm = TRUE)) %>%
  arrange(desc(nb_stations)) %>%
  head(5)

# Afficher le top 5 des arrondissements avec le plus grand nombre de stations
#kable(top_arrondissements, col.names = c("Arrondissements", "Stations"))
```

### Interprétations

\
Nous allons donc interpréter le top 5 des arrondissements avec le plus de stations uniques (dans notre échantillon de données) (interpréter l'ensemble des coefficients serait redondant et nous manquerons d'espace). Nous allons calculer la probabilité prédite que u15 = 1, donc cela sert à cibler les arrondissements problématiques.

```{r}
top_arrondissements$prob_mem0 = NA
top_arrondissements$prob_mem1 = NA

intercept <- coef(mod_u15_2)[1]  # Intercept
mm7 = coef(mod_u15_2)[25]
mem = coef(mod_u15_2)[21]

# Liste des arrondissements
arrondissements <- c("Le Plateau-Mont-Royal", "Ville-Marie", "Rosemont-La Petite-Patrie", "Villeray-Saint-Michel-Parc-Extension", "Le Sud-Ouest")

# Initialiser le tableau
data <- data.frame(
  arrond = arrondissements,
  nb_stations = c(157, 154, 99, 62, 56),
  prob_mem0 = NA,
  prob_mem1 = NA,
  mois = c("Août","Août","Août","Août","Août")
)

# Calculer les log-odds pour chaque arrondissement
for (i in 1:nrow(data)) {
  arrond_name <- data$arrond[i]
  if (arrond_name == "Le Plateau-Mont-Royal") {
    # Utiliser uniquement l'intercepte
    data$prob_mem0[i] <- round((exp(intercept+mm7)/(1+exp(intercept+mm7))*100), digits = 1)
  } else {
    # Utiliser le coefficient approprié pour les autres arrondissements
    coef_arrond <- coef(mod_u15_2)[paste0("arrond", arrond_name)]
    odd <- intercept + coef_arrond + mm7
    data$prob_mem0[i] <- round((exp(odd)/(1+exp(odd))*100), digits =1)
  }
}

for (i in 1:nrow(data)) {
  arrond_name <- data$arrond[i]
  if (arrond_name == "Le Plateau-Mont-Royal") {
    # Utiliser uniquement l'intercepte
    data$prob_mem1[i] <- round((exp(intercept+mm7+mem)/(1+exp(intercept+mm7+mem))*100), digits = 1)
  } else {
    # Utiliser le coefficient approprié pour les autres arrondissements
    coef_arrond <- coef(mod_u15_2)[paste0("arrond", arrond_name)]
    odd <- intercept + coef_arrond + mm7 +mem
    data$prob_mem1[i] <- round((exp(odd)/(1+exp(odd))*100), digits =1)
  }
}
```

```{r tab-prob}
# Afficher le tableau mis à jour
kable(data, col.names = c("Arrondissements", "Stations", "Prob. non-membres", "Prob.  membres", "Mois"), caption = "Tableau des probabilités")
```

Il est à noter qu'on peut inférer ces effets quand les autres variables (rain_bin et wkend) sont constantes

Comme il est possible de voir ci-dessus dans la table 1, selon ce deuxième modèle, les probabilités prédites changent selon l'arrondissement, le fait d'être un membre ou non et le mois d'utilisation. Par exemple, la probabilité que la durée moyenne des déplacements à une station du Plateau Mont-Royal au mois d'août est de 31,2% pour les non-membres et de 14,1% pour les membres. Il est à noter que ces interprétations sont significatives pour tous niveau de alpha raisonnable.

Il n'est pas très utile d'interpréter les deux autres constantes, car l'entreprise Bixi installe des stations permanentes au début de la saison. Si on voulait les interpréter on pourrait le faire comme cela : le weekend multiplie la cote de u15 de 1.75 en moyenne et lorsque les autres variables sont constantes. La pluie multiplie la cote de u15 de 0.74 en moyenne et lorsque les autres variables sont constantes. Ces deux interprétations sont significatives pour toutes valeurs d'alpha raisonnables.

## Conclusion sur l'effet des arrondissements

Selon les interprétations faites ultérieurement, l'entreprise Bixi est capable de cibler les arrondissements problématiques où la durée moyenne des déplacements a plus de probabilités d'être élevé. En effet, si on prend l'exemple de l'arrondissement Villeray-Saint-Michel-Parc-Extension, la probabilité est plutot élevé. Donc d'un point de vue d'affaire, il serait plus efficace d'installer des stations supplémentaires dans cet arrondissement. De plus, d'un point de vue général, il est efficace de fidéliser les utilisateurs à être membre, car il semble que les membres ont des voyages plus courts en moyenne (dans les arrondissements que nous avons interpréter).

### Limites

Le modèle inteprété possède des limites. En effet, il est impossible d'isoler l'effet des arrondissements selon si le client est abonné ou non. Il faudrait faire un modèle avec interactions entre `mem` et `arrond`. Par la suite, il serait nécessaire de tester si ce modèle est plus juste que le précédent. Or, par manque d'espace dans ce travail, nous n'allons pas réaliser cette analyse.

<!---De plus, l'entreprise peut se servir du graphique @ref(fig:fig-densite) pour trouver les arrondissements où il y a un débalancement entre la densité de stations et de populations en addition aux résultats du modèle pour régler le problème....`***`--->

```{r fig-densite, out.height = "30%", fig.align='center', fig.cap= "Densité de pop. et de stations par arrondissement"}
ylim.prim <- c(0, 20000)
ylim.sec <- c(0, 19.38271605)

b <- diff(ylim.prim)/diff(ylim.sec)
a <- ylim.prim[1] - b*ylim.sec[1]

adjustment_factor <- max(pop$dens) / max(pop$dens_stat)

p=ggplot(pop, aes(y = reorder(arrond, dens))) +
  geom_bar(aes(x = dens, fill = "Densité de population"), stat = "identity", color = "black") +
  geom_bar(aes(x = dens_stat * adjustment_factor, fill = "Densité de station"), stat = "identity", alpha = 0.7, color = "black") +
  scale_x_continuous("Densité", sec.axis = sec_axis(~ (. - a)/b, name = "Densité de station")) +
  labs(y = "Arrondissements", x = "Population") +
  theme(axis.text.y = element_text(angle = 0, hjust = 0)) +
  scale_fill_manual(values = c("Densité de population" = "skyblue", "Densité de station" = "#ff0000"),
                    name = "")
```

# Achalandage

À première vue, il est crucial d'avoir de l'information sur l'achalandage pour une entreprise comme BIXI. Notamment, lorsqu'il est question d'augmenter le nombre de vélos pour certaines stations, de faire les entretiens au bon moment de la journée, ou même de déterminer certaines zones d'expansion possible. À cet effet, nous avons des données sur le nombre d'utilisations en après-midi (`n_PM`), le nombre d'utilisations en matinée (`n_AM`) et le nombre d'utilisations total (`n_tot`). Avec ces données, nous essaierons d'observer qu'est-ce qui affecte l'achalandage, pour mieux équiper l'entreprise à répondre aux questions stratégiques mentionnées précédemment.

La question sur l'achalandage sera séparée en 3 parties. Quant à savoir qu'est ce qui affecte l'utilisation en matinée, en soirée et pour finir, on abordera l'utilisation totale. Enfin, nous comparerons les 3 métriques sur l'achalandage et conseillerons la compagnie sur les questions de planification des stations.

## Distribution

Tout d'abord, la figure \@ref(fig:distnPMnAMnTot) montre la distribution des déplacements en PM (à gauche), en AM (au centre) et au total pour la journée entière (à droite):

```{r distnPMnAMnTot, out.height = "90%",fig.align='center', fig.cap= "Histogramme du nombre total de déplacements en PM, AM et toute la journée (total)"}
#plot1 <- freq(ordered(dat_full$n_PM), plot = FALSE)

plot1<-ggplot(data.frame(x = dat_full$n_PM), aes(x)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 50) +
  labs(x='n_PM')

plot2<-ggplot(data.frame(x = dat_full$n_AM), aes(x)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 50) +
  labs(x="n_AM")

plot3<-ggplot(data.frame(x = dat_full$n_tot), aes(x)) +
  geom_histogram(fill = "lightblue", color = "black", bins = 50) +
  labs(x="n_tot")

grid.arrange(plot1,plot2,plot3, ncol = 3)

```

Dans les sections qui suivent, un modèle pour chacune de ses variables réponses sera développé.

## Modèle pour le nombre de déplacement en après-midi (n_PM)

### Distribution

Avant d'explorer un modèle, il est essentiel d'examiner la nature de la distribution des données. Dans ce contexte, l'illustration n_PM dans la figure \@ref(fig:distnPMnAMnTot) indique clairement qu'entre 0 et 10 utilisations, la fréquence est nettement plus élevée que pour les autres valeurs. En ajouta à ceci que le nombre d'utilisations est un décompte, on peut en déduire que la variable `n_PM` suit également une distribution de Poisson.

```{r fig-histnPM, out.height = "30%",fig.align='center', fig.cap= "Histogramme des déplacements en matinée"}

#fr <- freq(ordered(dat_full$n_PM), plot = FALSE)
#plot(fr)
```

### Modèle de base pour l'achalandage en après-midi

Dans le cadre du premier modèle portant sur l'achalandage en après-midi, l'objectif est d'évaluer, à l'aide d'un modèle sans interaction, comment les membres `mem`, la durée d'utilisation `dur`, l'arrondissement spécifique `arrond`, et le fait que la journée soit la fin de semaine `wkend`, influent sur le nombre d'utilisations durant cette période. Il est délibéré de ne pas inclure d'autres variables telles que la densité de population `density`, la superficie des arrondissements `superficie`, et d'autres covariables qui varient uniquement inter-arrondissement, car ces informations sont directement captées par la variable de l'arrondissement même `arrond`. Cela étant dit, les variables choisies pour les modèles qui suivent sont ceux qui peuvent varier intra-arrondissement en affectant le nombre d'utilisations en après-midi, sans que l'information soit captée par les autres covariables. Aussi, on n'ajoute pas les variables liées à la température pour la simple raison que ces variables sont codées de sorte à être les mêmes pour toute la région métropolitaine de Montréal. Par ailleurs, ce sont des variables qui sont hors du contrôle de l'entreprise, c'est-à-dire que même si l'on apprend que la pluie fait diminuer le nombre d'utilisations des Bixis en après-midi, l'entreprise ne peut rien y faire.Le modèle utilisé dans ce cas est : $dur = \beta_0 + \beta_{mem} + \beta_{wkend} + \beta_{dur} + \beta_{arrond}$

Autrement dit, ce que nous essayons de tester ici, c'est l'hypothès l'hypothèse H0 contre l'hypothèse H1 ci-dessous. C'est à dire que nous voulons savoir si au moins une des covariables à un effet significatif sur le nombre de déplacements en après-midi.

$$
\begin{aligned}
H_0 : \beta_{mem} = \beta_{wkend} = \beta_{dur} = \beta_{arrond} = 0\\
H_1: \text{Au moins un des } \beta_i \text{ est différent de } 0
\end{aligned}
$$

```{=html}
<!--$$H_0 : \beta_{mem} = \beta_{wkend} = \beta_{dur} = \beta_{arrond} = 0 $$
$H_1$ : au moin un des $\beta_i$ est différent de différent de 0-->
```
```{r}
mod_PM1 <- glm(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond ,data = dat_full, family = poisson)

```

```{r overdispAM, out.height = "30%",fig.align='center', fig.cap= "moyenne par rapport à la variance"}

fitted_values <- fitted(mod_PM1)
residuals <- residuals(mod_PM1, type = "pearson")  # Pearson residuals are used for Poisson regression

# Calcul dans chaque groupe
mean_values <- tapply(residuals^2, fitted_values, mean)
variance_values <- tapply(residuals^2, fitted_values, var)

# Graphique moyenne variance
plot(mean_values, variance_values, xlab = "Moyenne", ylab = "Variance",
     main = "",
     xlim = c(0, 12 ), ylim = c(0, max(250)))

# Add a reference line where mean = variance
abline(0, 1, col = "red")

```

Comme illustré dans la figure \@ref(fig:overdispAM), l'utilisation d'un modèle de Poisson révèle un problème de surdispersion, en particulier à partir du 3e groupe. Dans de telles situations, même un modèle quasi-Poisson ne convient pas pour résoudre ce problème, principalement parce que la surdispersion ne semnble pas être linéaire. Conséquemment, nous opterons pour l'utilisation d'un modèle binomial négatif. Le tableau de régression du modèle de base n'est pas présenté dans ce cas-ci, puisqu'il n'est pas approprié.

### Modèle binomial négatif

```{r}
mod.PMnb <- glm.nb(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond ,data = dat_full)
summary(mod.PMnb)

```

Selon le tableau de régression ci-dessus, il est possible de voir qu'en moyenne les déplacements en après-midi fait par les membres sont 2.24 fois plus élevés que ceux faits des non-membres. Par ailleurs, pendant les fins de semaine, il y a une diminution d'en moyenne 2% du nombre de déplacements en après-midi. Cela est surement dû au fait que les membres utilisent relativement moins Bixi pendant la fin de semaine (cette observation a été faite dans le premier rapport). Concernant la durée totale des déplacements, le tableau montre que pour chaque minute additionnelle d'utilisation de de bixi, le nombre de déplacements en après-midi augmente d'en moyenne de 1%. Enfin, il est possible d'observer que tous les coefficients des arrondissements sont négatifs, cela veut dire que l'arrondissement de référence, dans ce cas le plateau-mont royal, a un achalandage en après-midi plus important que tous les autres arrondissements. Bien sûr, ces observations sont seulement possibles lorsque toutes les variables restent inchangées. De plus, noter que ces interprétations sauf pour la variable `wkend` sont significatives pour tous niveau de alpha raisonnable.

Ainsi, la variable `wkend` à une valeur-p assez élevée, soit de 0.14. Ce qui indique que la diminution observée n'est pas statistiquement significative pour tout niveau de alpha raisonnable. En d'autres termes, nous n'avons pas assez de preuves pour affirmer de manière fiable que l'effet de la variable wkend est différent de zéro.

```{r}
Anova(mod.PMnb, type = 3)
```

En analysant le tableau Anova pour le modèle binomial négatif, on observe que, lors de la comparaison des modèles avec ou sans chaque variable, toutes les covariables présentent une significativité statistique lorsqu'on les ajoute 1 a 1, sauf `wkend` qui à été expliqué précédemment. Par conséquent, il est justifiable de rejeter l'hypothèse nulle (H0) et d'affirmer que, dans ce contexte, au moins un $\beta_i$ autre que `wkend` est différent de 0.

### Limite du modèle pour le nombre de déplacement en après-midi (n_PM)

Les limites du modèles présenté sont principalement le fait qu'il n'y ai pas d'interaction entre les covariables.Dans le contexte d'un modèle avec interaction, il est raisonnable de postuler qu'une interaction pertinente existe entre le statut de membre `mem` et l'arrondissement `arrond`. Cette conjecture se fonde sur l'idée que certains arrondissements affichent une densité de population plus élevée que d'autres. En conséquence, il est anticipé que les arrondissements densément peuplés génèreront naturellement un nombre plus élevé de déplacements en après-mid tout en étant plus sucéptible d'attirer davantage de membre.

Dans ce même ordre d'idée, il est plausible d'affirmer qu'il y a aussi une interaction entre le statut de membre `mem` et la durée totale des déplacements `dur`. La logique étant qu'il y a certains avantages tarifaires à être membre, de sorte que le comportement des déplacements en après-midi selon la durée de déplacement sera différent selon le statut d'abonnement.Enfin, la derniere interaction cohérente serait celle entre la durée totale de déplacement `dur` et les arondissements `arrond`. Pour ce cas spécifique il est possible de voir l'intéraction dans le graphique \@ref(fig:interDurArrond).

Cependant, la justification de ne pas inclure d'interactions dans le modèle repose principalement sur le fait que la plupart des interactions sont associées à la variable d'arrondissement `arrond`. Étant donné que `arrond` est une variable catégorielle avec près de 20 niveaux, l'introduction d'interactions créerait un grand nombre de coefficients, ce qui aurait pour effet d'augmenter considérablement la variance du modèle. Une approche alternative serait d'opter pour un modèle avec des effets aléatoires, ce qui nous permettrait de contrôler les effets fixes sans nécessairement introduire une multitude de paramètres additionnels.

```{r interDurArrond, out.height = "30%",fig.align='center', fig.cap= "Interaction entre la durée des déplacement et les arrondissements"}

ggplot(data = dat_full, aes(x = dur, y = n_PM, col = as.factor(arrond))) +
  geom_point()+
   geom_smooth(method = "lm", se = FALSE, formula = "y ~ x",
show.legend = FALSE, fullrange = T, size=0.5)+
  theme_minimal()
  
```

```{r}
mod_QPM2 <- glm(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond
                + as.factor(mem)*dur +as.factor(mem)*arrond
                ,data = dat_full, family = quasipoisson)
#summ(mod_QPM2,digits = getOption("jtools-digits", default = 4))


```

## Modèle pour le nombre de déplacement en avant-midi (n_AM)

### Distribution

L'analyse précédente pour le nombre de déplacements en PM peut aussi être effectué pour les déplacements en AM. Pour commencer, examinons la distribution du nombre de déplacements en AM d'après la figure \@ref(fig:distnPMnAMnTot) au centre vue précédemment.

```{r distnAM, out.height = "30%", fig.align = 'center', fig.cap = "Distribution de nAM"}
#frnAM <-(freq(ordered(dat_full$n_AM), plot = TRUE))
```

Comme on peut le constater avec la figure \@ref(fig:distnPMnAMnTot), la distribution n'est pas d'allure normale. Comme n_AM est une variable de dénombrement, la distribution s'approche plus d'une distribution de Poisson, n_AM a une moyenne de 4.3095 et une variance de 31.12.

```{r}
Moyenne_n_AM = mean(dat_full$n_AM)
Var_n_AM = var(dat_full$n_AM)
#summary(dat_full$n_AM)
#cat("Moyenne de n_AM :", Moyenne_n_AM,"Variance de n_AM :", Var_n_AM)
```

À première vue, la moyenne et la variance ne semblent pas égales et donc un modèle de Poisson ne semble pas être approprié. En calculant le paramètre de dispersion basé sur la déviance sur un modèle de Poisson incluant les variables explicatives `arrond` (arrondissement), `holiday` (jour férié), `mem` (membre), `wkend` (jour de fin de semaine) et `dur` (durée).

```{r}
mod_AM <- glm(n_AM ~ arrond + holiday + mem + wkend + dur,data = dat_full, family = poisson)
#summ(mod_AM,digits = getOption("jtools-digits", default = 4))
overdispersion_ratio <- mod_AM$deviance / mod_AM$df.residual
phi_2 = round(overdispersion_ratio, 2)
#cat("Le rapport deviance nous montre que Phi =", paste(round(overdispersion_ratio, 2), "> 1"))
```

Le rapport de deviance nous montre que Phi = `r phi_2` \> 1. La dristribution de n_AM et le rapport de déviance suggère de l'overdispersion avec un paramètre de dispersion de 1.97. La variance de n_AM étant plus élevée que la moyenne, un modèle de binomiale négative semblerait plus approprié (cette hypothèse sera testé prochainement).

### Modèle binomiale négatif

Le modèle de binomiale négative incluant les mêmes varibales explicatives utilisées pour faire obtenir le rapport de déviance est le suivant:

```{r}
mod.nbnAM <- glm.nb(n_AM ~ arrond + holiday + mem + wkend + dur, data = dat_full)
#options(digits = 4)
summary(mod.nbnAM)
#summ(mod.nbnAM, digits = getOption("jtools-digits", default = 4))

```

### Interprétation

On constate que toutes les variables explicatives sont significatives avec un niveau d'alpha de moins de 0.1%, nous pourrions donc rejeter l'hypothèse nulle (comme quoi Ho: Bj = 0 contre H1: Bj != 0, pour tous les coefficients). De plus, par exemple, on peut aussi faire le constat que la moyenne du nombre de déplacement en avant-midi est multiplié par exp(1.242) = 3.46 pour les membres comparativement aux non-membres lorsque toutes les autres variables sont fixes ce qui est plus élevé que la différence entre membre et non-membre pour le modèle en PM. Puis cette moyenne est multiplié par exp(-0.3096) = 0.73, donc une diminution d'environ 27% de la moyenne des déplacements en avant-midi pour les jours de fin de semaine comparativement à la semaine lorsque toutes les autres variables sont fixes. Pour les jours fériés, la moyenne de n_AM diminue d'environ 27% aussi. Comme pour le modèle de n_PM, tous les coefficients des arrondissements sont négatifs, cela veut dire le plateau-mont royal (arrondissement de référence) a un achalandage en avant-midi plus important que tous les autres arrondissements lorsque toutes les autres variables sont fixes.

De plus, d'après la sortie, on a une valeur de Theta de 4.804, qui est une estimation de l'inverse de k, k vaut donc = 1/4.804 = 0.208. On peut aussi faire le test H0: k = 0 contre H1: k \> 0. On obtient un LRT de 3320 et une valeur p avec la distribution khi-deux très petite. Ce qui suggère qu'on peut rejeter l'hypothèse pour tout niveau d'alpha raisonnable comme quoi le modèle de Poisson est une simplification adéquate du modèle de biomiale négative et conclure que le modèle de binomiale négative est nécessaire.

```{r}
lrt <- -2 * as.numeric(logLik(mod_AM) - logLik(mod.nbnAM))
pval <- pchisq(lrt, df = 1, lower.tail = FALSE)/2
```

### Limitations

Le modèle ci-dessus comporte les mêmes limitations que le modèle pour les déplacements en PM. En effet, celui-ci ne comporte pas d'interactions entre les variables. Cependant, nous sommes porter à croire qu'il en existe entre `mem` et `dur`, `mem` et `dur` ainsi qu'entre `dur` et les arondissements `arrond`.

### Conclusion AM

Pour conclure, les points importants à réaliser pour comprendre comment interragi le nombre de déplacement en AM avec les autres facteurs est que les membres ont tendance à effectuer plus de déplacement en AM que les non-membres, l'arrondissement avec le plus grand achalandage est l'arrondissement du plateau Mont-Royal, puis il semble avoir en moyenne plus de déplacement la semaine qu'en fin de semaine par jour. Cependant, il serait possible de pousser plus loin l'analyse en ajoutant des interactions et en vérifiant la significativité de celles-ci.

## Modèle pour le nombre total de déplacements partant d'une station tout au long de la journée

### Modélisation

Nous cherchons à comprendre les éléments qui ont un impact sur le nombre total de déplacement partant de chaque station (`n_tot`)

```{r, results='hide'}
bixi_withArr_df=read.csv("bixi1WithArrondissement.csv", stringsAsFactors = T)
bixi_withArr_df
```

```{r, results='hide'}
str(bixi_withArr_df)
```

```{r, results='hide'}
#Rajoutons une variable indicatrice wkend qui vaut 1 si c'est un weekend et 0 autrement
bixi_withArr_df$wkend <- as.integer(bixi_withArr_df$wday == "Saturday" | bixi_withArr_df$wday == "Sunday")
bixi_withArr_df
```

```{r, results='hide'}
summary(bixi_withArr_df)
```

```{r distNtot,out.height = "30%",fig.align='center', fig.cap="Distribution du nombre total de déplacement", results='hide', fig.keep='none'}
brx <- pretty(range(bixi_withArr_df$n_tot),
             n= nclass.Sturges(bixi_withArr_df$n_tot), min.n = 1)
ggplot(data = bixi_withArr_df, mapping = aes(x=n_tot)) +
 geom_histogram( breaks=brx, alpha=0.5) +
 scale_x_continuous(breaks = brx)
```

```{r, results='hide'}
n_tot.moy=mean(bixi_withArr_df$n_tot)
n_tot.var=var(bixi_withArr_df$n_tot)

print(paste("Moyenne: ", n_tot.moy,"| Variance: ", n_tot.var))
```

La figure de droite sur \@ref(fig:distnPMnAMnTot) nous montre la distribution du nombre total de déplacement. Elle ressemble beaucoup à celle d'une loi de poisson. De plus, il s'agit d'une variable de dénombrement. Par ailleurs, la moyenne de cette variable est d'environ `r round(n_tot.moy,0)` et sa variance d'environ `r round(n_tot.var,0)`, ce qui met en évidence un enjeu potentiel de sur-dispersion. De ce fait, le modèle poisson ne sera probablement pas le meilleur. Pour nous en convaincre, nous ferons un test formel pour le comparer au modèle binomial négatif. Par ailleurs, nous savons que les paramètres estimés des modèles poisson et quasi-poisson sont les mêmes. Ils diffèrent dans l'évaluation des erreurs types associés aux différents paramètres et donc aux valeurs-p correspondant. Nous comparerons donc les valeur-p du modèle poisson à celui de quasi-possoin afin de voir s'il y a une différence dans la pertinence des différentes variables considérées dans nos modèles.

Afin d'écrire nos modèles, nous devons déterminer les variables pertinentes à notre question de recherche. Rappelons, que notre objectif est de déterminer les éléments qui impactent le nombre total de déplacement. Nous allons donc considérer les variables liées à la météo (`temp` et `rain`), l'indicateur de jour férié (`holiday`), l'indicateur de membre (`mem`), l'indicateur de fin de semaine (`wkend`) et la durée totale (`dur`). L'inclusion de ce dernier peut paraitre moins évident. Il est possible que des stations dans lesquelles les bixis sont utilisés pour de longues périodes créent un problème de disponibilité qui impacterait le nombre de déplacements. Donc nous jugeons utile de contrôler pour cette variable pour bien mesurer l'impact des autres variables. L'indicateur de fin de semaine est une variable que nous avons introduite qui remplace la variable correspondant au jour de semaine (`wday`). Elle vaut 1 lorsque le jour de semaine est samedi ou dimanche et 0 autrement.

```{r, results='hide'}
n_tot_mod1.poisson = glm(n_tot ~ wkend + mem + holiday + dur + temp + rain, data=bixi_withArr_df, family = poisson(link = "log"))
out.n_tot_mod1.poisson <- summary(n_tot_mod1.poisson)
out.n_tot_mod1.poisson
```

<!-- La valeur-p associée à toutes les variables du modèle est très petite sauf celle de la variable indicatrice correspondant au mercredi. On peut donc conclure, qu'elles ont un effet marginal significatif sur le nombre total de déplacement en moyenne. Par ailleurs, il ne semble pas y avoir une différence significative entre la moyenne du nombre total de déplacement les mercredi par rapport au vendredi. De plus, il apparait qu'en moyenne il y a moins de déplacement les fins de semaine par rapport au vendredi après avoir ajusté pour les autres variables.  -->

```{r, results='hide'}
n_tot_mod1.quasi = glm(n_tot ~ wkend + mem + holiday + dur + temp + rain, data=bixi_withArr_df, family = quasipoisson)
out.n_tot_mod1.quasi <- summary(n_tot_mod1.quasi)
out.n_tot_mod1.quasi
```

```{r comparePvaluePoissonVsQuasi}
pvalue_compare_df = data.frame(poisson=out.n_tot_mod1.poisson$coefficients[,4], quasiPoisson=out.n_tot_mod1.quasi$coefficients[,4])
knitr::kable(pvalue_compare_df, caption = "Comparaison valeur-p: poisson Vs Quasi-poisson")
```

Le tableau \@ref(tab:comparePvaluePoissonVsQuasi) nous montre que toutes les valeur-p associées aux variables pour les deux modèles (modèle poisson Vs modèle quasi-poisson) sont très petites. On conclue donc, qu'autant avec le modèle poisson que le modèle quasi-poisson, toutes les variables incluses ont un effet marginal significatif sur le nombre total de déplacement en moyenne.

```{r}
n_tot_mod1.nb = glm.nb(n_tot ~ wkend + mem + holiday + dur + temp + rain, data=bixi_withArr_df)
out.n_tot_mod1.nb=summary(n_tot_mod1.nb)
out.n_tot_mod1.nb
out.n_tot_mod1.nb.coeff=out.n_tot_mod1.nb$coefficients
```

```{r, results='hide'}
k_stat=-2 * as.numeric(logLik(n_tot_mod1.poisson)-logLik(n_tot_mod1.nb))
k_stat

k_pvalue=pchisq(k_stat, df=1, lower.tail = FALSE)/2
k_pvalue
```

Avec la sortie ci-dessus, nous constatons qu'avec le modèle de binomiale négative, les journées fériées n'ont pas un impact significatif sur le nombre total de déplacement moyen. Toutefois, le modèle poisson est-il une simplification adéquate du modèle binomial négatif? Pour y répondre, nous testons $H_0: k=0$ contre $H_1: k > 0$. La valeur-p associée à ce test est `r k_pvalue` ce qui est très petit par rapport à n'importe quel niveau de significativité $\alpha$ acceptable. On rejète donc $H_0$ et on conclu que le modèle binomial négatif est plus approprié. Nous nous fions donc aux interprétations basées sur ce dernier.

### Interprétations

Plus la température augmente, plus le nombre total de déplacement moyen augmente. En fait, pour chaque degré d'augmentation de la température, le nombre total de déplacement augmente en moyenne de `r round((exp(out.n_tot_mod1.nb.coeff['temp','Estimate'])-1)*100,2)` % lorsque les autres variables demeurent constantes. Par contre, plus il y a des précipitations, moins il y a des déplacements (toujours lorsque les autres variables demeurent constantes) ce qui est logique. Il peut donc s'avérer utile de se doter d'un modèle prédictif de la météo pour déterminer les moments propices pour faire la maintenance de la flotte sans affecter la demande des usagers.

En moyenne le nombre total de déplacement au départ des stations pour les membres bixi est `r round(exp(out.n_tot_mod1.nb.coeff['mem','Estimate']),2)` fois plus élevé que les non-membres lorsque les autres variables restent constantes.

Il est intéressant de constater que, plus la durée totale des déplacements augmente, plus le nombre total de déplacements augmente. Celà nous laisse croire qu'il y a probablement une bonne gestion des flottes. C'est très important pour éviter des péneries de bixi dans les stations lorsque la demande augmente et que les usagers conservent plus longtemps leur vélo.

Enfin, il apparait qu'en moyenne le nombre total de déplacements est moins élevé les fins de semaine que pendant la semaine.

Le fait que les déplacements soient plus élevé pour les membres que les non-membres et que son usage se fait d'avantage en semaine qu'en fin de semaine, nous laisse penser que les bixi servent d'avantage à des habitudes courantes qui ont lieu en semaine. Probablement qu'ils sont surtout utilisés comme moyen de transport par les usagers pour se rendre au boulot. Toutefois, est-ce que l'utilisation des bixis en semaine par rapport aux fins de semaine est différente selon qu'on soit membre ou non-membre? Pour y répondre nous introduisons dans le modèle une interaction entre les variables `wkend` et `mem`.

```{r, results='hide'}
n_tot_mod2.nb = glm.nb(n_tot ~ wday + mem + holiday + dur + temp + rain, data=bixi_withArr_df)
out.n_tot_mod2.nb=summary(n_tot_mod2.nb)
out.n_tot_mod2.nb
```

```{r, results='hide'}
wday_emmeans <- emmeans(n_tot_mod2.nb, ~ wday)
contrast(wday_emmeans, method = "pairwise", adjust="none")
```

```{r, include=FALSE}
ggplot(data=bixi_withArr_df, mapping=aes(x=as.factor(wkend), y=n_tot)) + 
  geom_boxplot()

ggplot(data = bixi_withArr_df, mapping = aes(x=wkend, y=n_tot)) + 
  geom_point()
```

```{r, include=FALSE}
n_tot_mod2.poisson = glm(n_tot ~ wday + mem + holiday + dur + temp + rain, data=bixi_withArr_df, family = poisson(link = "log"))
summary(n_tot_mod2.poisson)
```

```{r}
n_tot_mod3.nb = glm.nb(n_tot ~ wkend*mem + holiday + dur + temp + rain, data=bixi_withArr_df)
out.n_tot_mod3.nb=summary(n_tot_mod3.nb)
out.n_tot_mod3.nb
out.n_tot_mod3.nb.coeff=out.n_tot_mod3.nb$coefficients
beta0=out.n_tot_mod3.nb.coeff[1,'Estimate']
beta1=out.n_tot_mod3.nb.coeff['wkend','Estimate']
beta2=out.n_tot_mod3.nb.coeff['mem','Estimate']
beta3=out.n_tot_mod3.nb.coeff['wkend:mem','Estimate']
```

Tout d'abord nous voyons dans la sortie du modèle ci-dessus que la valeur-p du paramètre estimé du terme d'interaction est très petite (1.53e-09) donc l'effet de l'interaction entre les variables `wkend` et `mem` est significatif pour n'importe quel niveau $\alpha$ acceptable. Autrement dit, la différence du nombre total de déplacement en semaine par rapport à la fin de semaine change selon qu'on soit membre ou non-membre. En fait pour les membres, l'utilisation totale en fin de semaine est en moyenne `r abs(round((exp(beta1+beta3)-1)*100,0))` % de moins que celle en semaine lorsque les autres variables restent inchangées. À contrario, pour les non-membres, l'utilisation totale en fin de semaine est en moyenne `r round((exp(beta1)-1)*100,0)`% de plus que celle en semaine lorsque les autres variables restent inchangées. Ces constats viennent étayer les découvertes faites lors de l'exploration des données dans la première partie du projet.

### Limites

Les modèles développés nous indiquent que plus la température augmente plus le nombre de déplacement augmente en moyenne. Mais intuitivement on peut croire qu'au delà d'une certaine température que les déplacements diminuent. Puisqu'il deviendrait très désagréable pour les usagers de se déplacer en bixi. Un tel comportement ne peut pas être bien capturé par nos modèles. Une autre limite de nos modèles concernent l'hypothèse de variance sous-jacente. En effet, nos modèles font l'hypothèse que la variance entre les différentes observations sont constantes. Or il est possible et même probable qu'il y ait une certaine corrélation entre les usagers d'une même station. En effet, chaque secteur ou quartier à comme un profil socio-économique et démographique qui lui est propre.

# Conclusions

Pour conclure, d'une part, nous utilisons la probabilité prédite des déplacements de plus ou moins de 15 minutes comme proxy pour la disponibilité des Bixi dans certains arrondissements. Ce type d'information peut être décisive pour une entreprise comme Bixi. Comme mentionné précédemment, ce proxy est imparfait, il semble néanmoins fournir une idée de quels arrondissements peuvent avoir des problèmes de disponibilité.\
D'autre part, nous examinons les facteurs influençant l'affluence à différentes périodes de la journée pour ensuite aborder le nombre total d'utilisations des Bixis. Nous constatons que les membres sollicitent davantage les vélos de l'entreprise le matin par rapport à l'après-midi, contrairement aux non-membres. Cette disparité est probablement liée à l'objectif d'utilisation : les non-membres utilisent davantage les Bixis de manière récréative, tandis que les membres les utilisent probablement comme moyen de transport habituel. Sur la base de ces observations, l'entreprise peut orienter ses stratégies de fidélisation. De plus, lors des deux périodes étudiées, le week-end présente une baisse moyenne d'utilisation des vélos. Comme observer dans l'utilisation durant toute la journée, cette baisse peut être attribuée au fait que relativement, les membres utilisent moins le service pendant la fin de semaine que les non-membres. Ces informations peuvent guider l'entreprise quant aux moments critiques pour la maintenance de leurs stations. Le nombre total de déplacements confirme cette conjecture. Par ailleurs, chacun de ces modèles présente des limitations significatives, soulignant l'importance d'améliorer leur précision en considérant simultanément les effets fixes et les interactions. C'est pourquoi nous avons envisagé l'utilisation d'effets aléatoires pour affiner nos observations.

# Contribution des membres de l'équipe

-   Modèle sur les voyages de plus ou moins de 15 minutes (James)
-   Modèle pour les déplacements en PM (Alfred)
-   Modèle pour les déplacements en AM (Samuel)
-   Modèle pour les déplacement totaux (Abdoul)
