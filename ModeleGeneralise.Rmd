---
title: "Projet BIXI - Partie 3: Modèle linéaire généralisés"
subtitle: "MATH60604 - Modélisation statistique"
author: "Abdoul Wassi Badirou, Alfred Assal, James Roy, Samuel Croteau"
date: "`r Sys.Date()`"
geometry: margin=1.5cm
output:
  # bookdown::html_document2:
  #   toc: yes
  #   number_sections: yes
  #   toc_float:
  #     collapsed: no
  # #   toc: yes
  # #   toc_depth: '3'
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 1
    extra_dependencies: ["flafter"]
  # pdf_document:
params:
  created_date: "2023-09-12"
header-includes:
- \usepackage{tikz}
- \usepackage{subcaption}
#- \usepackage{subfig}
- \usepackage{graphicx}
- \usepackage{sidecap}
- \usepackage{float}
- \usepackage{amsmath}
- \usepackage{ragged2e}
- \floatplacement{figure}{H}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE,message = FALSE,warning = FALSE,error = TRUE, fig.pos = "H")
```

```{r lib}
library(tidyverse)
library(readxl)
library(knitr)
library(googleway)
library(ggplot2)
library(car)
library(cleandata)
library(data.table)
library(kableExtra)
library(gridExtra)
library(jtools)
library(descr)
library(MASS)
```

```{r read}
dat = read.csv("bixifull.csv")
dat_full = read.csv("bixi_arrond_dens_full.csv") # Dataset avec les données sur les arrondissement, densité, etc...
dat_full$arrond <- factor(dat_full$arrond)
#hist(dat$n_tot)
#hist(dat$n_PM)
#hist(dat$n_AM)
```

```{r}
dat_full = dat_full %>% mutate(u15 = ifelse(avg > 15,1,0))
```

```{r}
dat_full <- dat_full %>%
  group_by(arrond) %>%
  mutate(nb_stations = n_distinct(station)) %>% 
  mutate(station_density = nb_stations/superficie)
```

# Introduction

Tout le monde ajouter un petit truc... Question: à suivre...

# Bin_u15min (James)

L'entreprise Bixi cherche à savoir qu'est-ce qui affecte la disponibilité dans ses stations. En effet, dans certaines stations ils ne restent plus de Bixi pour les autres usagers. Elle croit que cela peut être du à des utilisateurs qui font des voyagent trop long (plus de 15 minutes) et donc monopolisent les Bixi pour eux. En l'absence de variables sur la disponibilités, nous proposons d'utiliser une variable binaire `u15` qui prend la valeur de 1 si la durée moyenne à partir d'une certaine station à une certaine journée de l'année est supérieure à 15 minutes, 0 sinon. Bien que cette variable est imparfaite, il sera possible de cibler certaines conditions spécifiques (comme les arrondissements, les mois de l'année, etc.) qui agissent sur la disponibilité des Bixi.

```{r plot-u15, out.height = "22%", fig.align='center', fig.cap="Distribution de u15"}
barplot(table(dat_full$u15), col = c("red", "blue"), main = "", xlab = "Valeurs", ylab = "Fréquence")
```

Comme il est possible de le voir dans le graphique \@ref(fig:plot-u15), la variable cible est binaire, il faut ainsi faire une régression généralisée *logit.*

## Effets des arrondissements sur la variable `u15`

Étant donné que les stations sont installées au début de la saison, l'entreprise doit trouver les arrondissements problématiques. Il est donc possible d'ajuster un modèle simple pour voir les effets des différents arrondissements sur si la probabilité d'avoir des stations où le déplacement moyen est supérieur à 15 minutes.

```{r}
pop <- dat_full %>%
  group_by(arrond) %>%
  summarise(dens = mean(density, na.rm = TRUE),
            dens_stat = mean(station_density))
```

### Modèle 1

Étant donné que les stations sont installées au début de la saison, l'entreprise doit trouver les arrondissements problématiques. Il est donc possible d'ajuster un modèle simple pour voir les effets des différents arrondissements.

```{r, out.height = "10%"}
dat_full$arrond <- relevel(dat_full$arrond, ref = "Le Plateau-Mont-Royal")
mod_u15_1 = glm(u15 ~ arrond, data = dat_full, family = binomial(link = "logit"))
#summary(mod_u15_1)
summ(mod_u15_1)
```

#### Interprétations

```{r}
prob_lachine = round((exp(-1.22293+2.80111)/(1+exp(-1.22293+2.80111)))*100, digits = 1)
```

\

Selon ce premier modèle, on voit que comparé à l'arrondissement du Plateau-Mont-Royal, les déplacements faits dans tous les autres arrondissements et villes ont plus de chances d'être plus long que 15 minutes en moyennes. Cette observations est significative à au moins 99% pour tout les facteurs.

Par exemple, la probabilité que la moyenne des voyages dure plus de 15 minutes à une station dans l'arrondissement Lachine est de `r prob_lachine`%.

### Modèle 2

Maintenant, nous pouvons ajuster un modèle plus complexe pour voir s'il est possible de raffiner l'analyse.

```{r, out.height = "10%"}
mod_u15_2 = glm(u15 ~ arrond + mem + as.factor(mm), wkend + rain_bin, data = dat_full, family = binomial(link = "logit"))
summ(mod_u15_2)
```

Nous allons d'abord comparer le modèle avec le précédent avant de l'interpréter, car il se peut que le premier modèle soit une simplifcation correcte du deuxième modèle. C'est-à-dire que les deux modèles ne sont pas significativement différent en terme de qualité d'ajustement.

Nous allons donc faire le test suivant :

$H_0$ : Les modèles sont équivalents.

$H_1$ : Les modèles ne sont pas équivalents, donc l'ajout des nouvelles variables améliorent significativement l'ajustement du modèle.

```{r}
anova(mod_u15_1, mod_u15_2, test = "Chisq")
```

Ainsi, nous voyons que la valeur-P associée au test ci-dessus est inférieure à 0.1%, donc nous pouvons rejeter l'hypothèse nulle. En conclusion, le deuxième modèle s'ajuste mieux au données.

Dans ce cas, nous allons interpréter les résultats pour pouvoir dégager des informations pertinentes et stratégiques pour l'entreprise Bixi.

```{r tab-top}
top_arrondissements <- dat_full %>%
  group_by(arrond) %>%
  summarise(nb_stations = mean(nb_stations, na.rm = TRUE)) %>%
  arrange(desc(nb_stations)) %>%
  head(5)

# Afficher le top 5 des arrondissements avec le plus grand nombre de stations
#kable(top_arrondissements, col.names = c("Arrondissements", "Stations"))
```

#### Interprétations

\
Nous allons donc interpréter le top 5 des arrondissements avec le plus de stations uniques (dans notre échantillon de données).

```{r tab-prob, fig}
top_arrondissements$prob_mem0 = NA
top_arrondissements$prob_mem1 = NA

intercept <- coef(mod_u15_2)[1]  # Intercept
mm7 = coef(mod_u15_2)[25]
mem = coef(mod_u15_2)[21]

# Liste des arrondissements
arrondissements <- c("Le Plateau-Mont-Royal", "Ville-Marie", "Rosemont-La Petite-Patrie", "Villeray-Saint-Michel-Parc-Extension", "Le Sud-Ouest")

# Initialiser le tableau
data <- data.frame(
  arrond = arrondissements,
  nb_stations = c(157, 154, 99, 62, 56),
  prob_mem0 = NA,
  prob_mem1 = NA,
  mois = c("Août","Août","Août","Août","Août")
)

# Calculer les log-odds pour chaque arrondissement
for (i in 1:nrow(data)) {
  arrond_name <- data$arrond[i]
  if (arrond_name == "Le Plateau-Mont-Royal") {
    # Utiliser uniquement l'intercepte
    data$prob_mem0[i] <- round((exp(intercept+mm7)/(1+exp(intercept+mm7))*100), digits = 1)
  } else {
    # Utiliser le coefficient approprié pour les autres arrondissements
    coef_arrond <- coef(mod_u15_2)[paste0("arrond", arrond_name)]
    odd <- intercept + coef_arrond + mm7
    data$prob_mem0[i] <- round((exp(odd)/(1+exp(odd))*100), digits =1)
  }
}

for (i in 1:nrow(data)) {
  arrond_name <- data$arrond[i]
  if (arrond_name == "Le Plateau-Mont-Royal") {
    # Utiliser uniquement l'intercepte
    data$prob_mem1[i] <- round((exp(intercept+mm7+mem)/(1+exp(intercept+mm7+mem))*100), digits = 1)
  } else {
    # Utiliser le coefficient approprié pour les autres arrondissements
    coef_arrond <- coef(mod_u15_2)[paste0("arrond", arrond_name)]
    odd <- intercept + coef_arrond + mm7 +mem
    data$prob_mem1[i] <- round((exp(odd)/(1+exp(odd))*100), digits =1)
  }
}

# Afficher le tableau mis à jour
kable(data, col.names = c("Arrondissements", "Stations", "Prob. non-membres", "Prob.  membres", "Mois"), caption = "Tableau des probabilités")
```

Comme il est possible de voir ci-dessus dans le tableau 1, selon ce deuxième modèle, les probabilités prédites changent selon l'arrondissement, le fait d'être un membre ou non et le mois d'utilisation. Par exemple, la probabilité que la durée moyenne des déplacements à une station du Plateau Mont-Royale au mois d'août est de 31,2% pour les non-membres et de 14,1% pour les membres. Il est à noter que ces interprétations sont significatifs à 99,9%.

\newpage

## Conclusion sur l'effet des arrondissements

Selon les interprétations faites ultérieurement, l'entreprise Bixi est capable de cibler les arrondissements problématiques où la durée moyenne des déplacements a plus de probabilités d'être élevé. En effet, si on prend l'exemple de l'arrondissement Villeray-Saint-Michel-Parc-Extension, la probabilité est plutot élevé. Donc d'un point de vue d'affaire, il serait plus efficace d'installer des stations supplémentaires dans cet arrondissement. De plus, d'un point de vue général, il est efficace de fidéliser les utilisateurs à être membre, car il semble que les membres ont des voyages plus courts en moyenne. De plus, l'entreprise peut se servir du graphique \@ref(fig:fig-densite) pour trouver les arrondissements où il y a un débalancement entre la densité de stations et de populations en addition aux résultats du modèle pour régler le problème.

```{r fig-densite, out.height = "30%", fig.align='center', fig.cap= "Densité de pop. et de stations par arrondissement"}
ylim.prim <- c(0, 20000)
ylim.sec <- c(0, 19.38271605)

b <- diff(ylim.prim)/diff(ylim.sec)
a <- ylim.prim[1] - b*ylim.sec[1]

adjustment_factor <- max(pop$dens) / max(pop$dens_stat)

ggplot(pop, aes(y = reorder(arrond, dens))) +
  geom_bar(aes(x = dens, fill = "Densité de population"), stat = "identity", color = "black") +
  geom_bar(aes(x = dens_stat * adjustment_factor, fill = "Densité de station"), stat = "identity", alpha = 0.7, color = "black") +
  scale_x_continuous("Densité", sec.axis = sec_axis(~ (. - a)/b, name = "Densité de station")) +
  labs(y = "Arrondissements", x = "Population") +
  theme(axis.text.y = element_text(angle = 0, hjust = 0)) +
  scale_fill_manual(values = c("Densité de population" = "skyblue", "Densité de station" = "#ff0000"),
                    name = "")
```

# Achalandage

À première vue, il est crucial d'avoir de l'information sur l'achalandage pour une entreprise comme BIXI. Notamment, lorsqu'il est question d'augmenter le nombre de vélos pour certaines stations, de faire les entretiens au bon moment de la journée, ou même de déterminer certaines zones d'expansion possible. À cet effet, nous avons des données sur le nombre d'utilisations en après-midi(`n_PM`), le nombre d'utilisations en matinée (`n_AM`) et le nombre d'utilisations total(`n_tot`). Avec ces données, nous essaierons d'observer qu'est-ce qui affecte l'achalandage, pour mieux équiper l'entreprise à répondre aux questions stratégiques mentionnées précédemment.

La question sur l'achalandage sera séparée en 3 parties. Quant à savoir qu'est ce qui affecte l'utilisation en matinée, en soirée et pour finir, on abordera l'utilisation totale. Enfin, nous comparerons les 3 métriques sur l'achalandage et conseillerons la compagnie sur les questions de planification des stations.

## n_PM (Alfred)

Avant d'explorer un modèle, il est essentiel d'examiner la nature de la distribution des données. Dans ce contexte, la figure \@ref(fig:fig-histnPM) indique clairement qu'entre 0 et 10 utilisations, la fréquence est nettement plus élevée que pour les autres valeurs.En ajouta à ceci que le nombre d'utilisations est un décompte, on peut en déduire que la variable `n_PM` suit également une distribution de Poisson.

```{r fig-histnPM, out.height = "30%",fig.align='center', fig.cap= "Histogramme des déplacements en matinée"}

fr <- freq(ordered(dat_full$n_PM), plot = FALSE)
plot(fr)
```

### Modèle de base pour l'achalandage en après-midi

Dans le cadre du premier modèle portant sur l'achalandage en après-midi, l'objectif est d'évaluer, à l'aide d'un modèle sans interaction, comment les membres `mem`, la durée d'utilisation `dur`, l'arrondissement spécifique `arrond`, et le fait que la journée soit la fin de semaine `wkend`, influent sur le nombre d'utilisations durant cette période. Il est délibéré de ne pas inclure d'autres variables telles que la densité de population `density`, la superficie des arrondissements `superficie`, et d'autres covariables qui varient uniquement inter-arrondissement, car ces informations sont directement captées par la variable de l'arrondissement même. Cela étant dit, les variables choisies pour les modèles qui suivent sont ceux qui peuvent varier intra-arrondissement en affectant le nombre d'utilisations en après-midi, sans que l'information soit captée par les autres covariables. Aussi, on n'ajoute pas les variables liées à la température pour la simple raison que ces variables sont codées de sorte à être les mêmes pour toute la région métropolitaine de Montréal. Par ailleurs, ce sont des variables qui sont hors du contrôle de l'entreprise, c'est-à-dire que même si l'on apprend que la pluie fait diminuer le nombre d'utilisations des Bixis en après-midi, l'entreprise ne peut rien y faire.

Autrement dit, ce que nous essayons de tester ici, c'est l'hypothèse H0 contre l'hypothèse H1 ci-dessous. Nous voulons savoir si au moins une des covariables à un effet significatif sur le nombre de déplacements en après-midi.

<!-- $H_0 : \beta_{mem} = \beta_{wkend} = \beta_{dur} = \beta_{arrond} = 0 $ 
$H_1$ : au moin un des $\beta_i$ est différent de différent de 0-->
```{r}
mod_PM1 <- glm(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond ,data = dat_full, family = poisson)
summ(mod_PM1,digits = getOption("jtools-digits", default = 4))

# Calcul du rapport deviance/df.residual
overdispersion_ratio <- mod_PM1$deviance / mod_PM1$df.residual

# Affichage du rapport avec un commentaire sur la surdispersion
cat("Le rapport deviance nous montre que : Phi =", paste(round(overdispersion_ratio, 2), ", > 1"))

```

Selon le tableau de régression ci-dessus, il est possible de voir qu'en moyenne les déplacements en après-midi fait par les membres sont 2.9 fois plus élevés que ceux faits des non-membres. Par ailleurs, pendant les fins de semaine, il y a une diminution d'en moyenne 5% du nombre de déplacements en après-midi. Cela est surement dû au fait que les membres utilisent moins Bixi pendant la fin de semaine (cette observation a été faite dans le premier rapport). Concernant la durée totale des déplacements, le tableau montre que pour chaque minute additionnelle d'utilisation de de bixi, le nombre de déplacements en après-midi augmente d'en moyenne de 1%.Enfin, il est possible d'observer que tous les coefficients des arrondissements sont négatifs, cela veut dire que l'arrondissement de référence, dans ce cas le plateau-mont royal, a un achalandage en après-midi plus important que tous les autres arrondissements. Bien sûr, ces observations sont seulement possibles lorsque toutes les variables restent inchangées.

Cela étant dit, en regardant le rapport des déviances, on peut conclure qu'il y a un problème de surdispersion. Conséquemment, cela entraîne des intervalles de confiance incorrects et des tests de significativité inappropriés. Il nous est alors, impossible de vérifier le test d'hypothèse mentionnée précédemment. Pour combler ce problème, il est préférable d'utiliser un modèle quasi-poisson.

```{r}
mod_QPM1 <- glm(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond ,data = dat_full, family = quasipoisson)
summ(mod_QPM1)
Anova(mod_QPM1, type = 3)

```

En analysant le tableau Anova pour le modèle quasi-Poisson, on observe que, lors de la comparaison des modèles avec ou sans chaque variable, toutes les covariables présentent une significativité statistique. Par conséquent, il est justifiable de rejeter l'hypothèse nulle (H0) et d'affirmer que, dans ce contexte, toutes les covariables diffèrent significativement de zéro. Autrement dit, l'entreprise peut se fier aux covariables incluses dans le modèle pour expliquer le nombre de déplacements en après-midi.

### Modèle ajusté avec intéraction

Dans le contexte du modèle avec interaction, il est raisonnable de postuler qu'une interaction pertinente existe entre le statut de membre `mem` et l'arrondissement `arrond`. Cette conjecture se fonde sur l'idée que certains arrondissements affichent une densité de population plus élevée que d'autres. En conséquence, il est anticipé que les arrondissements densément peuplés génèreront naturellement un nombre plus élevé de déplacements en après-mid tout en étant plus sucéptible d'attirer davantage de membre. 

Dans ce même ordre d'idée, il est plausible d'affirmer qu'il y aura aussi une interaction entre le statut de membre `mem` et la durée totale des déplacements `dur`. La logique étant qu'il y a certains avantages tarifaires à être membres, de sorte que le comportement des déplacements en après-midi selon la durée de déplacement sera différent selon le statut d'abonnement.

Enfin, la derniere interaction cohérente serait celle entre la durée totale de déplacement `dur` et les arondissements `arrond`. Pour ce cas spécifique il est possible de voir l'intéraction dans le graphique \@ref(fig:interDurArrond). 


```{r interDurArrond, out.height = "30%",fig.align='center', fig.cap= "Intéraction entre la durée des déplacement et les arrondissements"}

ggplot(data = dat_full, aes(x = dur, y = n_PM, col = as.factor(arrond))) +
  geom_point()+
   geom_smooth(method = "lm", se = FALSE, formula = "y ~ x",
show.legend = FALSE, fullrange = T, size=0.5)+
  theme_minimal()
  
```

```{r}
mod_QPM2 <- glm(n_PM ~ as.factor(mem) + as.factor(wkend) + dur + arrond
                + as.factor(mem)*dur +as.factor(mem)*arrond
                ,data = dat_full, family = quasipoisson)
summ(mod_QPM2,digits = getOption("jtools-digits", default = 4))


```


## n_AM

L'analyse précédente pour le nombre de déplacements en PM peut aussi être effectué pour les déplacements en AM. Pour commencer, examinons la distribution du nombre de déplacements en AM:

```{r distnAM, out.height = "30%", fig.align = 'center', fig.cap = "Distribution de nAM"}
frnAM <-(freq(ordered(dat_full$n_AM), plot = TRUE))
```

Comme on peut le constater avec la figure \@ref(fig:distnAM), la distribution n'est pas normale. Les statistiques de n_AM sont les suivantes:

```{r}
Moyenne_n_AM = mean(dat_full$n_AM)
Var_n_AM = var(dat_full$n_AM)
summary(dat_full$n_AM)
cat("Moyenne de n_AM :", Moyenne_n_AM,"Variance de n_AM :", Var_n_AM)
```
### Modèle de base pour l'achalandage en avant-midi

À première vue, la moyenne et la variance ne semblent pas égales et donc un modèle de Poisson ne semble pas être approprié. Calculons ainsi le paramètre de dispersion basé sur la déviance sur un modèle de Poisson avec les variables explicatives pertinentes:

```{r}
mod_AM <- glm(n_AM ~ arrond + holiday + mem + wkend + dur,data = dat_full, family = poisson)
summ(mod_PM1,digits = getOption("jtools-digits", default = 4))
overdispersion_ratio <- mod_AM$deviance / mod_AM$df.residual
cat("Le rapport deviance nous montre que Phi =", paste(round(overdispersion_ratio, 2), "> 1"))
```
Le rapport de déviance suggère de l'overdispersion avec un paramètre de dispersion de 1.97. La variance de n_AM étant plus élevée que la moyenne, un modèle de binomiale négative semblerait plus approprié. À partir de ce modèle, il sera aussi possible de tester l'hyphotèse comme quoi un modèle de Poisson est une simplification adéquate ou non du modèle de binomiale négative. Le modèle de binomiale négative est le suivant:

```{r}
mod.nbnAM <- glm.nb(n_AM ~ arrond + holiday + mem + wkend + dur, data = dat_full)
#options(digits = 4)
#summary(mod.nbnAM)
summ(mod.nbnAM, digits = getOption("jtools-digits", default = 4))

```
On constate que toutes les variables explicatives sont significatives, nous pourrions donc jeter l'hypothèse nulle (comme quoi Ho: Bj = 0 contre H1: Bj != 0) avec un niveau d'alpha de moins de 0.1%. De plus, par exemple, on peut aussi faire le constat que la moyenne du nombre de déplacement en avant-midi est multiplié par exp(1.790) = 5.99 pour les membres comparativement aux non-membres lorsque toutes les autres variables sont fixes, puis cette moyenne est multiplié par exp(-0.271) = 0.76, donc une diminution d'environ 24% de la moyenne des déplacements en avant-midi pour les jours de fin de semaine comparativement à la semaine lorsque toutes les autres variables sont fixes. Pour les jours fériés, la moyenne de n_AM diminue d'environ 18%. Comme pour le modèle de n_PM, tous les coefficients des arrondissements sont négatifs, cela veut dire le plateau-mont royal, a un achalandage en avant-midi plus important que tous les autres arrondissements lorsque toutes les autres variables sont fixes.

De plus, d'après la sortie, on a une valeur de Theta de 2.3269, qui est une estimation de l'inverse de k, k vaut donc = 1/2.3269 = 0.43. On peut aussi faire le test H0: k = 0 contre H1: k > 0.
On obtient un LRT de 3320 et une valeur p avec la distribution khi-deux très petite. Ce qui suggère qu'on peut rejeter l'hypothèse comme quoi le modèle de Poisson est une simplification adéquate du modèle de biomiale négative et conclure que le modèle de binomiale négative est plus approprié.

```{r}
lrt <- -2 * as.numeric(logLik(mod_AM) - logLik(mod.nbnAM))
pval <- pchisq(lrt, df = 1, lower.tail = FALSE)/2
```

### Modèle ajusté avec interactions

Les mêmes interactions utilisées pour le modèle en PM sont aussi pertinentes pour ce modèle. Soit, une interaction entre `mem` et `arrond`, une avec `mem` et `dur`, puis l'une avec `dur` et `arrond`. Ce modèle ajusté avec les interactions est le suivant:


```{r}
#mod.nbnAMa <- glm.nb(n_AM ~ arrond + holiday + mem + wkend + dur + arrond*mem + arrond*dur + mem*dur, data = dat_full)
#options(scipen = 999)
#summary(mod.nbnAMa,digits = 4)
#Anova(mod.nbnAMa, type = 3)
```

## n_tot (Abdoul)
